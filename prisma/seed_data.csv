id,arxivId,submitter,authors,title,comments,journalRef,doi,reportNo,categories,license,abstract,versions,updateDate,authorsParsed
1,704.2201,Hassan Satori,"H. Satori, M. Harti and N. Chenfour",Arabic Speech Recognition System using CMU-Sphinx4,"5 pages, 3 figures and 2 tables, in French",,,,cs.CL cs.AI,,"  In this paper we present the creation of an Arabic version of Automated
Speech Recognition System (ASR). This system is based on the open source
Sphinx-4, from the Carnegie Mellon University. Which is a speech recognition
system based on discrete hidden Markov models (HMMs). We investigate the
changes that must be made to the model to adapt Arabic voice recognition.
  Keywords: Speech recognition, Acoustic model, Arabic language, HMMs,
CMUSphinx-4, Artificial intelligence.
","[{'version': 'v1', 'created': 'Tue, 17 Apr 2007 17:04:26 GMT'}]",2007-05-23,"[['Satori', 'H.', ''], ['Harti', 'M.', ''], ['Chenfour', 'N.', '']]"
2,704.3662,Tian-Jian Jiang,"Mike Tian-Jian Jiang, James Zhan, Jaimie Lin, Jerry Lin, Wen-Lien Hsu",An Automated Evaluation Metric for Chinese Text Entry,8 pages,"Jiang, Mike Tian-Jian, et al. ""Robustness analysis of adaptive
  chinese input methods."" Advances in Text Input Methods (WTIM 2011) (2011): 53",,,cs.HC cs.CL,,"  In this paper, we propose an automated evaluation metric for text entry. We
also consider possible improvements to existing text entry evaluation metrics,
such as the minimum string distance error rate, keystrokes per character, cost
per correction, and a unified approach proposed by MacKenzie, so they can
accommodate the special characteristics of Chinese text. Current methods lack
an integrated concern about both typing speed and accuracy for Chinese text
entry evaluation. Our goal is to remove the bias that arises due to human
factors. First, we propose a new metric, called the correction penalty (P),
based on Fitts' law and Hick's law. Next, we transform it into the approximate
amortized cost (AAC) of information theory. An analysis of the AAC of Chinese
text input methods with different context lengths is also presented.
","[{'version': 'v1', 'created': 'Fri, 27 Apr 2007 05:34:10 GMT'}]",2013-10-29,"[['Jiang', 'Mike Tian-Jian', ''], ['Zhan', 'James', ''], ['Lin', 'Jaimie', ''], ['Lin', 'Jerry', ''], ['Hsu', 'Wen-Lien', '']]"
3,704.3665,Tian-Jian Jiang,"Mike Tian-Jian Jiang, Deng Liu, Meng-Juei Hsieh, Wen-Lien Hsu",On the Development of Text Input Method - Lessons Learned,10 pages,,,,cs.CL cs.HC,,"  Intelligent Input Methods (IM) are essential for making text entries in many
East Asian scripts, but their application to other languages has not been fully
explored. This paper discusses how such tools can contribute to the development
of computer processing of other oriental languages. We propose a design
philosophy that regards IM as a text service platform, and treats the study of
IM as a cross disciplinary subject from the perspectives of software
engineering, human-computer interaction (HCI), and natural language processing
(NLP). We discuss these three perspectives and indicate a number of possible
future research directions.
","[{'version': 'v1', 'created': 'Fri, 27 Apr 2007 05:58:32 GMT'}]",2007-05-23,"[['Jiang', 'Mike Tian-Jian', ''], ['Liu', 'Deng', ''], ['Hsieh', 'Meng-Juei', ''], ['Hsu', 'Wen-Lien', '']]"
4,704.3708,Bernat Corominas-Murtra BCM,Bernat Corominas-Murtra,Network statistics on early English Syntax: Structural criteria,"New abstract. Due to a mistake, abstract from V1 was from an old,
  draft version of the work. The content of the paper is exactly the same,
  except on section ""measures"" where a new cite has been added. 28 pag",,,,cs.CL,,"  This paper includes a reflection on the role of networks in the study of
English language acquisition, as well as a collection of practical criteria to
annotate free-speech corpora from children utterances. At the theoretical
level, the main claim of this paper is that syntactic networks should be
interpreted as the outcome of the use of the syntactic machinery. Thus, the
intrinsic features of such machinery are not accessible directly from (known)
network properties. Rather, what one can see are the global patterns of its use
and, thus, a global view of the power and organization of the underlying
grammar. Taking a look into more practical issues, the paper examines how to
build a net from the projection of syntactic relations. Recall that, as opposed
to adult grammars, early-child language has not a well-defined concept of
structure. To overcome such difficulty, we develop a set of systematic criteria
assuming constituency hierarchy and a grammar based on lexico-thematic
relations. At the end, what we obtain is a well defined corpora annotation that
enables us i) to perform statistics on the size of structures and ii) to build
a network from syntactic relations over which we can perform the standard
measures of complexity. We also provide a detailed example.
","[{'version': 'v1', 'created': 'Fri, 27 Apr 2007 17:13:37 GMT'}, {'version': 'v2', 'created': 'Mon, 30 Apr 2007 10:06:50 GMT'}]",2007-05-23,"[['Corominas-Murtra', 'Bernat', '']]"
5,704.3886,W Saba,Walid S. Saba,A Note on Ontology and Ordinary Language,"19 pages, 1 figure",,,,cs.AI cs.CL,,"  We argue for a compositional semantics grounded in a strongly typed ontology
that reflects our commonsense view of the world and the way we talk about it.
Assuming such a structure we show that the semantics of various natural
language phenomena may become nearly trivial.
","[{'version': 'v1', 'created': 'Mon, 30 Apr 2007 17:55:39 GMT'}, {'version': 'v2', 'created': 'Tue, 1 May 2007 13:43:32 GMT'}, {'version': 'v3', 'created': 'Wed, 2 May 2007 18:13:22 GMT'}, {'version': 'v4', 'created': 'Thu, 3 May 2007 08:34:47 GMT'}, {'version': 'v5', 'created': 'Fri, 4 May 2007 17:49:03 GMT'}, {'version': 'v6', 'created': 'Mon, 7 May 2007 16:04:50 GMT'}]",2007-05-23,"[['Saba', 'Walid S.', '']]"
6,705.0462,Nicolas Tabareau,"Paul-Andr\'e Melli\`es (PPS), Nicolas Tabareau (PPS)",Resource modalities in game semantics,,,,,math.CT cs.CL,,"  The description of resources in game semantics has never achieved the
simplicity and precision of linear logic, because of a misleading conception:
the belief that linear logic is more primitive than game semantics. We advocate
instead the contrary: that game semantics is conceptually more primitive than
linear logic. Starting from this revised point of view, we design a categorical
model of resources in game semantics, and construct an arena game model where
the usual notion of bracketing is extended to multi- bracketing in order to
capture various resource policies: linear, af&#64257;ne and exponential.
","[{'version': 'v1', 'created': 'Thu, 3 May 2007 13:44:54 GMT'}]",2007-05-23,"[['Melliès', 'Paul-André', '', 'PPS'], ['Tabareau', 'Nicolas', '', 'PPS']]"
7,705.1161,Lillian Lee,Lillian Lee,"IDF revisited: A simple new derivation within the Robertson-Sp\""arck
  Jones probabilistic model","To appear, Proceedings of SIGIR 2007, poster paper (2 pages)",,,,cs.IR cs.CL,,"  There have been a number of prior attempts to theoretically justify the
effectiveness of the inverse document frequency (IDF). Those that take as their
starting point Robertson and Sparck Jones's probabilistic model are based on
strong or complex assumptions. We show that a more intuitively plausible
assumption suffices. Moreover, the new assumption, while conceptually very
simple, provides a solution to an estimation problem that had been deemed
intractable by Robertson and Walker (1997).
","[{'version': 'v1', 'created': 'Tue, 8 May 2007 20:08:13 GMT'}]",2007-05-23,"[['Lee', 'Lillian', '']]"
8,705.4676,Daniel Lemire,Daniel Lemire and Owen Kaser,"Recursive n-gram hashing is pairwise independent, at best",See software at https://github.com/lemire/rollinghashcpp,Computer Speech & Language 24(4): 698-710 (2010),10.1016/j.csl.2009.12.001,,cs.DB cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Many applications use sequences of n consecutive symbols (n-grams). Hashing
these n-grams can be a performance bottleneck. For more speed, recursive hash
families compute hash values by updating previous values. We prove that
recursive hash families cannot be more than pairwise independent. While hashing
by irreducible polynomials is pairwise independent, our implementations either
run in time O(n) or use an exponential amount of memory. As a more scalable
alternative, we make hashing by cyclic polynomials pairwise independent by
ignoring n-1 bits. Experimentally, we show that hashing by cyclic polynomials
is is twice as fast as hashing by irreducible polynomials. We also show that
randomized Karp-Rabin hash families are not pairwise independent.
","[{'version': 'v1', 'created': 'Thu, 31 May 2007 18:41:28 GMT'}, {'version': 'v2', 'created': 'Mon, 8 Dec 2008 17:39:33 GMT'}, {'version': 'v3', 'created': 'Fri, 6 Feb 2009 21:37:14 GMT'}, {'version': 'v4', 'created': 'Mon, 23 Feb 2009 16:23:41 GMT'}, {'version': 'v5', 'created': 'Wed, 5 Aug 2009 03:01:20 GMT'}, {'version': 'v6', 'created': 'Wed, 19 Aug 2009 14:39:54 GMT'}, {'version': 'v7', 'created': 'Wed, 4 Jan 2012 20:37:05 GMT'}, {'version': 'v8', 'created': 'Mon, 6 Jun 2016 15:18:03 GMT'}]",2016-06-07,"[['Lemire', 'Daniel', ''], ['Kaser', 'Owen', '']]"
9,707.0895,Damian H. Zanette,Damian H. Zanette,Segmentation and Context of Literary and Musical Sequences,To appear in Complex Systems,,,,cs.CL physics.data-an,,"  We test a segmentation algorithm, based on the calculation of the
Jensen-Shannon divergence between probability distributions, to two symbolic
sequences of literary and musical origin. The first sequence represents the
successive appearance of characters in a theatrical play, and the second
represents the succession of tones from the twelve-tone scale in a keyboard
sonata. The algorithm divides the sequences into segments of maximal
compositional divergence between them. For the play, these segments are related
to changes in the frequency of appearance of different characters and in the
geographical setting of the action. For the sonata, the segments correspond to
tonal domains and reveal in detail the characteristic tonal progression of such
kind of musical composition.
","[{'version': 'v1', 'created': 'Fri, 6 Jul 2007 01:45:05 GMT'}]",2007-07-09,"[['Zanette', 'Damian H.', '']]"
10,707.1913,Daniel Lemire,"Owen Kaser, Daniel Lemire","Removing Manually-Generated Boilerplate from Electronic Texts:
  Experiments with Project Gutenberg e-Books","short version appeared in CASCON 2007 proceedings, available from
  http://portal.acm.org/citation.cfm?id=1321246 Source code at
  https://github.com/lemire/gutenberg-headers",,,"Department of CSAS, UNBSJ Technical Report TR-07-001",cs.DL cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Collaborative work on unstructured or semi-structured documents, such as in
literature corpora or source code, often involves agreed upon templates
containing metadata. These templates are not consistent across users and over
time. Rule-based parsing of these templates is expensive to maintain and tends
to fail as new documents are added. Statistical techniques based on frequent
occurrences have the potential to identify automatically a large fraction of
the templates, thus reducing the burden on the programmers. We investigate the
case of the Project Gutenberg corpus, where most documents are in ASCII format
with preambles and epilogues that are often copied and pasted or manually
typed. We show that a statistical approach can solve most cases though some
documents require knowledge of English. We also survey various technical
solutions that make our approach applicable to large data sets.
","[{'version': 'v1', 'created': 'Fri, 13 Jul 2007 02:30:10 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Aug 2009 19:57:15 GMT'}, {'version': 'v3', 'created': 'Mon, 22 Aug 2016 21:02:58 GMT'}]",2016-08-24,"[['Kaser', 'Owen', ''], ['Lemire', 'Daniel', '']]"
11,707.3269,Laurent Romary,"Laurent Romary (INRIA Lorraine - LORIA), Nancy Ide (INRIA Lorraine -
  LORIA)",International Standard for a Linguistic Annotation Framework,,"Natural Language Engineering 10, 3-4 (09/2004) 211-225",,,cs.CL,,"  This paper describes the Linguistic Annotation Framework under development
within ISO TC37 SC4 WG1. The Linguistic Annotation Framework is intended to
serve as a basis for harmonizing existing language resources as well as
developing new ones.
","[{'version': 'v1', 'created': 'Sun, 22 Jul 2007 15:24:48 GMT'}]",2007-07-24,"[['Romary', 'Laurent', '', 'INRIA Lorraine - LORIA'], ['Ide', 'Nancy', '', 'INRIA Lorraine -\n  LORIA']]"
12,707.327,Laurent Romary,"Laurent Romary (INRIA Lorraine - LORIA), Nancy Ide, Adam Kilgarriff",A Formal Model of Dictionary Structure and Content,,"Dans Euralex 2000 Euralex 2000, Stuttgart : Allemagne (2000)",,,cs.CL,,"  We show that a general model of lexical information conforms to an abstract
model that reflects the hierarchy of information found in a typical dictionary
entry. We show that this model can be mapped into a well-formed XML document,
and how the XSL transformation language can be used to implement a semantics
defined over the abstract model to enable extraction and manipulation of the
information in any format.
","[{'version': 'v1', 'created': 'Sun, 22 Jul 2007 15:25:27 GMT'}]",2007-07-24,"[['Romary', 'Laurent', '', 'INRIA Lorraine - LORIA'], ['Ide', 'Nancy', ''], ['Kilgarriff', 'Adam', '']]"
13,707.3559,Wilson Wong,Wilson Wong,"Practical Approach to Knowledge-based Question Answering with Natural
  Language Understanding and Advanced Reasoning","Master of Science thesis, National Technical University College of
  Malaysia, 2005",,,,cs.CL cs.AI cs.HC cs.IR,,"  This research hypothesized that a practical approach in the form of a
solution framework known as Natural Language Understanding and Reasoning for
Intelligence (NaLURI), which combines full-discourse natural language
understanding, powerful representation formalism capable of exploiting
ontological information and reasoning approach with advanced features, will
solve the following problems without compromising practicality factors: 1)
restriction on the nature of question and response, and 2) limitation to scale
across domains and to real-life natural language text.
","[{'version': 'v1', 'created': 'Tue, 24 Jul 2007 14:30:27 GMT'}]",2007-07-25,"[['Wong', 'Wilson', '']]"
14,707.3972,Ted Pedersen,Ted Pedersen,Learning Probabilistic Models of Word Sense Disambiguation,195 pages,"PhD dissertation, May 1998, Department of Computer Science and
  Engineering, Southern Methodist University",,,cs.CL cs.AI,,"  This dissertation presents several new methods of supervised and unsupervised
learning of word sense disambiguation models. The supervised methods focus on
performing model searches through a space of probabilistic models, and the
unsupervised methods rely on the use of Gibbs Sampling and the Expectation
Maximization (EM) algorithm. In both the supervised and unsupervised case, the
Naive Bayesian model is found to perform well. An explanation for this success
is presented in terms of learning rates and bias-variance decompositions.
","[{'version': 'v1', 'created': 'Thu, 26 Jul 2007 17:02:40 GMT'}]",2009-09-29,"[['Pedersen', 'Ted', '']]"
15,708.0694,Maurice H. T. Ling,"Maurice HT Ling, Christophe Lefevre, Kevin R. Nicholas, and Feng Lin","Reconstruction of Protein-Protein Interaction Pathways by Mining
  Subject-Verb-Objects Intermediates","2nd IAPR Workshop on Pattern Recognition in Bioinformatics (PRIB
  2007). 14 pages, 4 figures","Ling, Maurice HT, Lefevre, Christophe, Nicholas, Kevin R, Lin,
  Feng. 2007. In J.C. Ragapakse, B. Schmidt, and G. Volkert (Eds.), PRIB 2007.
  Lecture Notes in Bioinformatics 4774: 286-299. Springer-Verlag.",,,cs.IR cs.CL cs.DL,,"  The exponential increase in publication rate of new articles is limiting
access of researchers to relevant literature. This has prompted the use of text
mining tools to extract key biological information. Previous studies have
reported extensive modification of existing generic text processors to process
biological text. However, this requirement for modification had not been
examined. In this study, we have constructed Muscorian, using MontyLingua, a
generic text processor. It uses a two-layered generalization-specialization
paradigm previously proposed where text was generically processed to a suitable
intermediate format before domain-specific data extraction techniques are
applied at the specialization layer. Evaluation using a corpus and experts
indicated 86-90% precision and approximately 30% recall in extracting
protein-protein interactions, which was comparable to previous studies using
either specialized biological text processing tools or modified existing tools.
Our study had also demonstrated the flexibility of the two-layered
generalization-specialization paradigm by using the same generalization layer
for two specialized information extraction tasks.
","[{'version': 'v1', 'created': 'Mon, 6 Aug 2007 01:22:46 GMT'}]",2007-08-07,"[['Ling', 'Maurice HT', ''], ['Lefevre', 'Christophe', ''], ['Nicholas', 'Kevin R.', ''], ['Lin', 'Feng', '']]"
16,708.1564,Stasinos Konstantopoulos,Stasinos Konstantopoulos,Learning Phonotactics Using ILP,,"Special Issue of the WEB-SLS Journal: The Language Sections of the
  ESSLLI-01 Student Session. 2002",,,cs.CL,,"  This paper describes experiments on learning Dutch phonotactic rules using
Inductive Logic Programming, a machine learning discipline based on inductive
logical operators. Two different ways of approaching the problem are
experimented with, and compared against each other as well as with related work
on the task. The results show a direct correspondence between the quality and
informedness of the background knowledge and the constructed theory,
demonstrating the ability of ILP to take good advantage of the prior domain
knowledge available. Further research is outlined.
","[{'version': 'v1', 'created': 'Sat, 11 Aug 2007 13:09:27 GMT'}]",2007-08-14,"[['Konstantopoulos', 'Stasinos', '']]"
17,708.2303,W Saba,Walid S. Saba,Compositional Semantics Grounded in Commonsense Metaphysics,,,,,cs.AI cs.CL,,"  We argue for a compositional semantics grounded in a strongly typed ontology
that reflects our commonsense view of the world and the way we talk about it in
ordinary language. Assuming the existence of such a structure, we show that the
semantics of various natural language phenomena may become nearly trivial.
","[{'version': 'v1', 'created': 'Fri, 17 Aug 2007 01:15:11 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Aug 2007 17:48:14 GMT'}]",2009-09-29,"[['Saba', 'Walid S.', '']]"
18,709.0116,Fionn Murtagh,Fionn Murtagh,On Ultrametric Algorithmic Information,"Forthcoming, Computer Journal. Minor corrections 29 Oct. 2007","Computer Journal, 53, 405-416, 2010",10.1093/comjnl/bxm084,,cs.AI cs.CL,,"  How best to quantify the information of an object, whether natural or
artifact, is a problem of wide interest. A related problem is the computability
of an object. We present practical examples of a new way to address this
problem. By giving an appropriate representation to our objects, based on a
hierarchical coding of information, we exemplify how it is remarkably easy to
compute complex objects. Our algorithmic complexity is related to the length of
the class of objects, rather than to the length of the object.
","[{'version': 'v1', 'created': 'Sun, 2 Sep 2007 17:00:40 GMT'}, {'version': 'v2', 'created': 'Sat, 29 Sep 2007 11:21:51 GMT'}]",2011-06-14,"[['Murtagh', 'Fionn', '']]"
19,709.2401,Timothy Baldwin,Timothy Baldwin,Bootstrapping Deep Lexical Resources: Resources for Courses,,"In Proceedings of the ACL-SIGLEX 2005 Workshop on Deep Lexical
  Acquisition, Ann Arbor, USA, pp. 67-76",,,cs.CL,,"  We propose a range of deep lexical acquisition methods which make use of
morphological, syntactic and ontological language resources to model word
similarity and bootstrap from a seed lexicon. The different methods are
deployed in learning lexical items for a precision grammar, and shown to each
have strengths and weaknesses over different word classes. A particular focus
of this paper is the relative accessibility of different language resource
types, and predicted ``bang for the buck'' associated with each in deep lexical
acquisition applications.
","[{'version': 'v1', 'created': 'Sat, 15 Sep 2007 01:37:21 GMT'}]",2007-09-18,"[['Baldwin', 'Timothy', '']]"
20,710.0009,Adam Lipowski,Adam Lipowski and Dorota Lipowska,"Bio-linguistic transition and Baldwin effect in an evolutionary
  naming-game model","7 pages, minor changes, accepted in Int.J.Mod.Phys.C, proceedings of
  Max Born Symp. Wroclaw (Poland), Sept. 2007. Java applet is available at
  http://spin.amu.edu.pl/~lipowski/biolin.html or
  http://www.amu.edu.pl/~lipowski/biolin.html","Int.J.Mod.Phys. C vol.19, pp. 399-407 (2008)",10.1142/S0129183108012248,,cs.CL cond-mat.stat-mech cs.AI physics.soc-ph q-bio.PE,,"  We examine an evolutionary naming-game model where communicating agents are
equipped with an evolutionarily selected learning ability. Such a coupling of
biological and linguistic ingredients results in an abrupt transition: upon a
small change of a model control parameter a poorly communicating group of
linguistically unskilled agents transforms into almost perfectly communicating
group with large learning abilities. When learning ability is kept fixed, the
transition appears to be continuous. Genetic imprinting of the learning
abilities proceeds via Baldwin effect: initially unskilled communicating agents
learn a language and that creates a niche in which there is an evolutionary
pressure for the increase of learning ability.Our model suggests that when
linguistic (or cultural) processes became intensive enough, a transition took
place where both linguistic performance and biological endowment of our species
experienced an abrupt change that perhaps triggered the rapid expansion of
human civilization.
","[{'version': 'v1', 'created': 'Mon, 1 Oct 2007 09:39:49 GMT'}, {'version': 'v2', 'created': 'Sun, 21 Oct 2007 13:20:17 GMT'}]",2009-11-13,"[['Lipowski', 'Adam', ''], ['Lipowska', 'Dorota', '']]"
21,710.0105,Dmitrii Manin,Dmitrii Manin,Zipf's Law and Avoidance of Excessive Synonymy,47 pages; fixed reference list missing in v.1,"Main text in Cognitive Science, 32 (7) 2008, pp. 1075 - 1098;
  Appendix A TBP separately in J. Quant. Ling.",10.1080/03640210802020003,,cs.CL physics.soc-ph,,"  Zipf's law states that if words of language are ranked in the order of
decreasing frequency in texts, the frequency of a word is inversely
proportional to its rank. It is very robust as an experimental observation, but
to date it escaped satisfactory theoretical explanation. We suggest that Zipf's
law may arise from the evolution of word semantics dominated by expansion of
meanings and competition of synonyms.
","[{'version': 'v1', 'created': 'Sun, 30 Sep 2007 03:21:54 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Oct 2007 03:36:45 GMT'}]",2009-01-22,"[['Manin', 'Dmitrii', '']]"
22,710.0169,Andrew Krizhanovsky A,A. A. Krizhanovsky,"Evaluation experiments on related terms search in Wikipedia: Information
  Content and Adapted HITS (In Russian)","10 pages, 1 figure, 3 tables, in Russian, short version of the paper
  to be published in Proceedings of the Wiki-Conference 2007, Russia, St.
  Petersburg, October 27-28. http://tinyurl.com/2czd6e ; v3: +figure; v4: typo
  in Table 3; v5: +desc (res_hypo formula); v6: typo",,,,cs.IR cs.CL,,"  The classification of metrics and algorithms search for related terms via
WordNet, Roget's Thesaurus, and Wikipedia was extended to include adapted HITS
algorithm. Evaluation experiments on Information Content and adapted HITS
algorithm are described. The test collection of Russian word pairs with
human-assigned similarity judgments is proposed.
  -----
  Klassifikacija metrik i algoritmov poiska semanticheski blizkih slov v
tezaurusah WordNet, Rozhe i jenciklopedii Vikipedija rasshirena adaptirovannym
HITS algoritmom. S pomow'ju jeksperimentov v Vikipedii oceneny metrika
Information Content i adaptirovannyj algoritm HITS. Predlozhen resurs dlja
ocenki semanticheskoj blizosti russkih slov.
","[{'version': 'v1', 'created': 'Mon, 1 Oct 2007 16:04:52 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Oct 2007 06:21:01 GMT'}, {'version': 'v3', 'created': 'Sat, 6 Oct 2007 15:38:57 GMT'}, {'version': 'v4', 'created': 'Sun, 14 Oct 2007 14:44:03 GMT'}, {'version': 'v5', 'created': 'Sun, 4 Nov 2007 11:05:26 GMT'}, {'version': 'v6', 'created': 'Wed, 16 Jan 2008 17:31:14 GMT'}]",2008-01-16,"[['Krizhanovsky', 'A. A.', '']]"
23,710.0225,Dmitry Lande,"D.V. Lande, A.A. Snarskii",On the role of autocorrelations in texts,"5 pages, 4 figures, 5 references",,,,cs.CL,,"  The task of finding a criterion allowing to distinguish a text from an
arbitrary set of words is rather relevant in itself, for instance, in the
aspect of development of means for internet-content indexing or separating
signals and noise in communication channels. The Zipf law is currently
considered to be the most reliable criterion of this kind [3]. At any rate,
conventional stochastic word sets do not meet this law. The present paper deals
with one of possible criteria based on the determination of the degree of data
compression.
","[{'version': 'v1', 'created': 'Mon, 1 Oct 2007 08:23:24 GMT'}]",2007-10-02,"[['Lande', 'D. V.', ''], ['Snarskii', 'A. A.', '']]"
24,710.0228,Dmitry Lande,"S. Braichevsky, D. Lande, A. Snarskii","On the fractal nature of mutual relevance sequences in the Internet news
  message flows","6 pages, 56 figures",,,,cs.CL,,"  In the task of information retrieval the term relevance is taken to mean
formal conformity of a document given by the retrieval system to user's
information query. As a rule, the documents found by the retrieval system
should be submitted to the user in a certain order. Therefore, a retrieval
perceived as a selection of documents formally solving the user's query, should
be supplemented with a certain procedure of processing a relevant set. It would
be natural to introduce a quantitative measure of document conformity to query,
i.e. the relevance measure. Since no single rule exists for the determination
of the relevance measure, we shall consider two of them which are the simplest
in our opinion. The proposed approach does not suppose any restrictions and can
be applied to other relevance measures.
","[{'version': 'v1', 'created': 'Mon, 1 Oct 2007 08:31:56 GMT'}]",2007-10-02,"[['Braichevsky', 'S.', ''], ['Lande', 'D.', ''], ['Snarskii', 'A.', '']]"
25,710.1481,Stasinos Konstantopoulos,Stasinos Konstantopoulos,What's in a Name?,"Presented at the Computational Phonology Workshop, 6th Intl. Conf.
  Recent Advances in NLP, Borovets, Bulgaria, September 2007",,,,cs.CL cs.AI,,"  This paper describes experiments on identifying the language of a single name
in isolation or in a document written in a different language. A new corpus has
been compiled and made available, matching names against languages. This corpus
is used in a series of experiments measuring the performance of general
language models and names-only language models on the language identification
task. Conclusions are drawn from the comparison between using general language
models and names-only language models and between identifying the language of
isolated names and the language of very short document fragments. Future
research directions are outlined.
","[{'version': 'v1', 'created': 'Mon, 8 Oct 2007 08:36:32 GMT'}]",2007-10-09,"[['Konstantopoulos', 'Stasinos', '']]"
26,710.1511,Damian H. Zanette,Damian H. Zanette,Demographic growth and the distribution of language sizes,To appear in Int. J. Mod. Phys. C (2008),,10.1142/S0129183108012042,,physics.data-an cs.CL physics.soc-ph,,"  It is argued that the present log-normal distribution of language sizes is,
to a large extent, a consequence of demographic dynamics within the population
of speakers of each language. A two-parameter stochastic multiplicative process
is proposed as a model for the population dynamics of individual languages, and
applied over a period spanning the last ten centuries. The model disregards
language birth and death. A straightforward fitting of the two parameters,
which statistically characterize the population growth rate, predicts a
distribution of language sizes in excellent agreement with empirical data.
Numerical simulations, and the study of the size distribution within language
families, validate the assumptions at the basis of the model.
","[{'version': 'v1', 'created': 'Mon, 8 Oct 2007 11:16:51 GMT'}]",2009-11-13,"[['Zanette', 'Damian H.', '']]"
27,710.2446,Catherine Recanati,"Catherine Recanati (LIPN), Nicoleta Rogovschi (LIPN), Youn\`es Bennani
  (LIPN)","The structure of verbal sequences analyzed with unsupervised learning
  techniques",,"Dans Proceedings - The 3rd Language & Technology Conference: Human
  Language Technologies as a Challenge for Computer Science and Linguistics,
  Poznan : Pologne (2007)",,,cs.CL cs.AI cs.LG,,"  Data mining allows the exploration of sequences of phenomena, whereas one
usually tends to focus on isolated phenomena or on the relation between two
phenomena. It offers invaluable tools for theoretical analyses and exploration
of the structure of sentences, texts, dialogues, and speech. We report here the
results of an attempt at using it for inspecting sequences of verbs from French
accounts of road accidents. This analysis comes from an original approach of
unsupervised training allowing the discovery of the structure of sequential
data. The entries of the analyzer were only made of the verbs appearing in the
sentences. It provided a classification of the links between two successive
verbs into four distinct clusters, allowing thus text segmentation. We give
here an interpretation of these clusters by applying a statistical analysis to
independent semantic annotations.
","[{'version': 'v1', 'created': 'Fri, 12 Oct 2007 12:44:11 GMT'}]",2007-10-15,"[['Recanati', 'Catherine', '', 'LIPN'], ['Rogovschi', 'Nicoleta', '', 'LIPN'], ['Bennani', 'Younès', '', 'LIPN']]"
28,710.2674,James Ford,James Ford,Linguistic Information Energy,"10 pages, 7 graphs",,,,cs.CL cs.IT math.IT,,"  In this treatment a text is considered to be a series of word impulses which
are read at a constant rate. The brain then assembles these units of
information into higher units of meaning. A classical systems approach is used
to model an initial part of this assembly process. The concepts of linguistic
system response, information energy, and ordering energy are defined and
analyzed. Finally, as a demonstration, information energy is used to estimate
the publication dates of a series of texts and the similarity of a set of
texts.
","[{'version': 'v1', 'created': 'Sun, 14 Oct 2007 16:09:53 GMT'}]",2007-10-16,"[['Ford', 'James', '']]"
29,710.2852,Sebastien Hinderer,"Patrick Blackburn (INRIA Lorraine - LORIA), S\'ebastien Hinderer
  (INRIA Lorraine - LORIA)",Generating models for temporal representations,,Dans Recent Advances in Natural Language Processing (2007) 69-75,,,cs.CL,,"  We discuss the use of model building for temporal representations. We chose
Polish to illustrate our discussion because it has an interesting aspectual
system, but the points we wish to make are not language specific. Rather, our
goal is to develop theoretical and computational tools for temporal model
building tasks in computational semantics. To this end, we present a
first-order theory of time and events which is rich enough to capture
interesting semantic distinctions, and an algorithm which takes minimal models
for first-order theories and systematically attempts to ``perturb'' their
temporal component to provide non-minimal, but semantically significant,
models.
","[{'version': 'v1', 'created': 'Mon, 15 Oct 2007 15:45:13 GMT'}]",2007-10-16,"[['Blackburn', 'Patrick', '', 'INRIA Lorraine - LORIA'], ['Hinderer', 'Sébastien', '', 'INRIA Lorraine - LORIA']]"
30,710.2988,Paul Bedaride,Paul Bedaride (INRIA Lorraine - Loria),Using Description Logics for Recognising Textual Entailment,,"Dans 19th European Summer School in Logic, Language and
  Information (2007) 11-21",,,cs.CL,,"  The aim of this paper is to show how we can handle the Recognising Textual
Entailment (RTE) task by using Description Logics (DLs). To do this, we propose
a representation of natural language semantics in DLs inspired by existing
representations in first-order logic. But our most significant contribution is
the definition of two novel inference tasks: A-Box saturation and subgraph
detection which are crucial for our approach to RTE.
","[{'version': 'v1', 'created': 'Tue, 16 Oct 2007 09:16:24 GMT'}]",2007-10-17,"[['Bedaride', 'Paul', '', 'INRIA Lorraine - Loria']]"
31,710.3285,Tamara Tretjakova,Tretjakova Tamara,Nontraditional Scoring of C-tests,"4 pages, in Russian",,,,cs.CY cs.CL,,"  In C-tests the hypothesis of items local independence is violated, which
doesn't permit to consider them as real tests. It is suggested to determine the
distances between separate C-test items (blanks) and to combine items into
clusters. Weights, inversely proportional to the number of items in
corresponding clusters, are assigned to items. As a result, the C-test
structure becomes similar to the structure of classical tests, without
violation of local independence hypothesis.
","[{'version': 'v1', 'created': 'Wed, 17 Oct 2007 12:42:39 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Oct 2007 07:50:21 GMT'}]",2007-10-18,"[['Tamara', 'Tretjakova', '']]"
32,710.3502,Stergos Afantenos,"Stergos D. Afantenos, V. Karkaletsis, P. Stamatopoulos and C. Halatsis","Using Synchronic and Diachronic Relations for Summarizing Multiple
  Documents Describing Evolving Events","45 pages, 6 figures. To appear in the Journal of Intelligent
  Information Systems",,10.1007/s10844-006-0025-9,,cs.CL cs.IR,,"  In this paper we present a fresh look at the problem of summarizing evolving
events from multiple sources. After a discussion concerning the nature of
evolving events we introduce a distinction between linearly and non-linearly
evolving events. We present then a general methodology for the automatic
creation of summaries from evolving events. At its heart lie the notions of
Synchronic and Diachronic cross-document Relations (SDRs), whose aim is the
identification of similarities and differences between sources, from a
synchronical and diachronical perspective. SDRs do not connect documents or
textual elements found therein, but structures one might call messages.
Applying this methodology will yield a set of messages and relations, SDRs,
connecting them, that is a graph which we call grid. We will show how such a
grid can be considered as the starting point of a Natural Language Generation
System. The methodology is evaluated in two case-studies, one for linearly
evolving events (descriptions of football matches) and another one for
non-linearly evolving events (terrorist incidents involving hostages). In both
cases we evaluate the results produced by our computational systems.
","[{'version': 'v1', 'created': 'Thu, 18 Oct 2007 13:24:26 GMT'}]",2007-10-19,"[['Afantenos', 'Stergos D.', ''], ['Karkaletsis', 'V.', ''], ['Stamatopoulos', 'P.', ''], ['Halatsis', 'C.', '']]"
33,710.4516,"Thomas Sch\""urmann","Thomas Sch\""urmann and Peter Grassberger",The predictability of letters in written english,"3 pages, 4 figures","Fractals, Vol. 4, No. 1 (1996) 1-5",10.1142/S0218348X96000029,,physics.soc-ph cs.CL stat.ML,,"  We show that the predictability of letters in written English texts depends
strongly on their position in the word. The first letters are usually the least
easy to predict. This agrees with the intuitive notion that words are well
defined subunits in written languages, with much weaker correlations across
these units than within them. It implies that the average entropy of a letter
deep inside a word is roughly 4 times smaller than the entropy of the first
letter.
","[{'version': 'v1', 'created': 'Wed, 24 Oct 2007 17:23:13 GMT'}, {'version': 'v2', 'created': 'Fri, 26 Oct 2007 16:46:30 GMT'}]",2017-04-24,"[['Schürmann', 'Thomas', ''], ['Grassberger', 'Peter', '']]"
34,710.5382,Stergos Afantenos,Stergos D. Afantenos,"Some Reflections on the Task of Content Determination in the Context of
  Multi-Document Summarization of Evolving Events","5 pages, 2 figures","Edited by Galia Angelova, Kalina Bontcheva, Ruslan Mitkov, Nicolas
  Nicolov, and Nikolai Nikolov, Recent Advances in Natural Language Processing
  (RANLP 2007). Borovets, Bulgaria: INCOMA, 12-16",,,cs.CL,,"  Despite its importance, the task of summarizing evolving events has received
small attention by researchers in the field of multi-document summariztion. In
a previous paper (Afantenos et al. 2007) we have presented a methodology for
the automatic summarization of documents, emitted by multiple sources, which
describe the evolution of an event. At the heart of this methodology lies the
identification of similarities and differences between the various documents,
in two axes: the synchronic and the diachronic. This is achieved by the
introduction of the notion of Synchronic and Diachronic Relations. Those
relations connect the messages that are found in the documents, resulting thus
in a graph which we call grid. Although the creation of the grid completes the
Document Planning phase of a typical NLG architecture, it can be the case that
the number of messages contained in a grid is very large, exceeding thus the
required compression rate. In this paper we provide some initial thoughts on a
probabilistic model which can be applied at the Content Determination stage,
and which tries to alleviate this problem.
","[{'version': 'v1', 'created': 'Mon, 29 Oct 2007 10:48:48 GMT'}]",2007-10-30,"[['Afantenos', 'Stergos D.', '']]"
35,711.0666,Bouselmi Ghazi,"Ghazi Bouselmi (INRIA Lorraine - LORIA), Dominique Fohr (INRIA
  Lorraine - LORIA), Irina Illina (INRIA Lorraine - LORIA), Jean-Paul Haton
  (INRIA Lorraine - LORIA)","Discriminative Phoneme Sequences Extraction for Non-Native Speaker's
  Origin Classification",,"Dans ISSPA, International Symposium on Signal Processing and its
  Applications (2007)",,,cs.CL,,"  In this paper we present an automated method for the classification of the
origin of non-native speakers. The origin of non-native speakers could be
identified by a human listener based on the detection of typical pronunciations
for each nationality. Thus we suppose the existence of several phoneme
sequences that might allow the classification of the origin of non-native
speakers. Our new method is based on the extraction of discriminative sequences
of phonemes from a non-native English speech database. These sequences are used
to construct a probabilistic classifier for the speakers' origin. The existence
of discriminative phone sequences in non-native speech is a significant result
of this work. The system that we have developed achieved a significant correct
classification rate of 96.3% and a significant error reduction compared to some
other tested techniques.
","[{'version': 'v1', 'created': 'Mon, 5 Nov 2007 15:20:47 GMT'}]",2007-11-06,"[['Bouselmi', 'Ghazi', '', 'INRIA Lorraine - LORIA'], ['Fohr', 'Dominique', '', 'INRIA\n  Lorraine - LORIA'], ['Illina', 'Irina', '', 'INRIA Lorraine - LORIA'], ['Haton', 'Jean-Paul', '', 'INRIA Lorraine - LORIA']]"
36,711.0811,Bouselmi Ghazi,"Ghazi Bouselmi (INRIA Lorraine - LORIA), Dominique Fohr (INRIA
  Lorraine - LORIA), Irina Illina (INRIA Lorraine - LORIA)","Combined Acoustic and Pronunciation Modelling for Non-Native Speech
  Recognition",,Dans InterSpeech 2007 (2007),,,cs.CL,,"  In this paper, we present several adaptation methods for non-native speech
recognition. We have tested pronunciation modelling, MLLR and MAP non-native
pronunciation adaptation and HMM models retraining on the HIWIRE foreign
accented English speech database. The ``phonetic confusion'' scheme we have
developed consists in associating to each spoken phone several sequences of
confused phones. In our experiments, we have used different combinations of
acoustic models representing the canonical and the foreign pronunciations:
spoken and native models, models adapted to the non-native accent with MAP and
MLLR. The joint use of pronunciation modelling and acoustic adaptation led to
further improvements in recognition accuracy. The best combination of the above
mentioned techniques resulted in a relative word error reduction ranging from
46% to 71%.
","[{'version': 'v1', 'created': 'Tue, 6 Nov 2007 08:23:49 GMT'}]",2007-11-07,"[['Bouselmi', 'Ghazi', '', 'INRIA Lorraine - LORIA'], ['Fohr', 'Dominique', '', 'INRIA\n  Lorraine - LORIA'], ['Illina', 'Irina', '', 'INRIA Lorraine - LORIA']]"
37,711.1038,Bouselmi Ghazi,"Ghazi Bouselmi (INRIA Lorraine - LORIA), Dominique Fohr (INRIA
  Lorraine - LORIA), Irina Illina (INRIA Lorraine - LORIA), Jean-Paul Haton
  (INRIA Lorraine - LORIA)","Am\'elioration des Performances des Syst\`emes Automatiques de
  Reconnaissance de la Parole pour la Parole Non Native",,"Dans TAIMA'07, Traitement et Analyse de l'Information : M\'ethodes
  et Applications (2007)",,,cs.CL,,"  In this article, we present an approach for non native automatic speech
recognition (ASR). We propose two methods to adapt existing ASR systems to the
non-native accents. The first method is based on the modification of acoustic
models through integration of acoustic models from the mother tong. The
phonemes of the target language are pronounced in a similar manner to the
native language of speakers. We propose to combine the models of confused
phonemes so that the ASR system could recognize both concurrent
pronounciations. The second method we propose is a refinment of the
pronounciation error detection through the introduction of graphemic
constraints. Indeed, non native speakers may rely on the writing of words in
their uttering. Thus, the pronounctiation errors might depend on the characters
composing the words. The average error rate reduction that we observed is
(22.5%) relative for the sentence error rate, and 34.5% (relative) in word
error rate.
","[{'version': 'v1', 'created': 'Wed, 7 Nov 2007 08:51:09 GMT'}]",2007-11-08,"[['Bouselmi', 'Ghazi', '', 'INRIA Lorraine - LORIA'], ['Fohr', 'Dominique', '', 'INRIA\n  Lorraine - LORIA'], ['Illina', 'Irina', '', 'INRIA Lorraine - LORIA'], ['Haton', 'Jean-Paul', '', 'INRIA Lorraine - LORIA']]"
38,711.136,Damian H. Zanette,Damian H. Zanette,Analytical approach to bit-string models of language evolution,To appear in Int. J. Mod. Phys. C,,10.1142/S0129183108012340,,physics.soc-ph cs.CL,,"  A formulation of bit-string models of language evolution, based on
differential equations for the population speaking each language, is introduced
and preliminarily studied. Connections with replicator dynamics and diffusion
processes are pointed out. The stability of the dominance state, where most of
the population speaks a single language, is analyzed within a mean-field-like
approximation, while the homogeneous state, where the population is evenly
distributed among languages, can be exactly studied. This analysis discloses
the existence of a bistability region, where dominance coexists with
homogeneity as possible asymptotic states. Numerical resolution of the
differential system validates these findings.
","[{'version': 'v1', 'created': 'Thu, 8 Nov 2007 21:05:38 GMT'}]",2009-11-13,"[['Zanette', 'Damian H.', '']]"
39,711.2023,Peter Turney,Peter D. Turney (National Research Council of Canada),Empirical Evaluation of Four Tensor Decomposition Algorithms,related work available at http://purl.org/peter.turney/,,,"ERB-1152, NRC-49877",cs.LG cs.CL cs.IR,,"  Higher-order tensor decompositions are analogous to the familiar Singular
Value Decomposition (SVD), but they transcend the limitations of matrices
(second-order tensors). SVD is a powerful tool that has achieved impressive
results in information retrieval, collaborative filtering, computational
linguistics, computational vision, and other fields. However, SVD is limited to
two-dimensional arrays of data (two modes), and many potential applications
have three or more modes, which require higher-order tensor decompositions.
This paper evaluates four algorithms for higher-order tensor decomposition:
Higher-Order Singular Value Decomposition (HO-SVD), Higher-Order Orthogonal
Iteration (HOOI), Slice Projection (SP), and Multislice Projection (MP). We
measure the time (elapsed run time), space (RAM and disk space requirements),
and fit (tensor reconstruction accuracy) of the four algorithms, under a
variety of conditions. We find that standard implementations of HO-SVD and HOOI
do not scale up to larger tensors, due to increasing RAM requirements. We
recommend HOOI for tensors that are small enough for the available RAM and MP
for larger tensors.
","[{'version': 'v1', 'created': 'Tue, 13 Nov 2007 16:28:47 GMT'}]",2007-11-14,"[['Turney', 'Peter D.', '', 'National Research Council of Canada']]"
40,711.227,Igor M. Suslov,"I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,
  Russia)",Can a Computer Laugh ?,"English translation of the paper in Russian; 18 pages, 6 figures
  included","Computer Chronicle (Moscow), 1994, issue 1, p.1",,,cs.CL cs.AI q-bio.NC,,"  A computer model of ""a sense of humour"" suggested previously
[arXiv:0711.2058,0711.2061], relating the humorous effect with a specific
malfunction in information processing, is given in somewhat different
exposition. Psychological aspects of humour are elaborated more thoroughly. The
mechanism of laughter is formulated on the more general level. Detailed
discussion is presented for the higher levels of information processing, which
are responsible for a perception of complex samples of humour. Development of a
sense of humour in the process of evolution is discussed.
","[{'version': 'v1', 'created': 'Wed, 14 Nov 2007 18:32:09 GMT'}]",2007-11-27,"[['Suslov', 'I. M.', '', 'P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia']]"
41,711.2444,Richard Moot,"Richard Moot (INRIA Futurs, Labri)",Proof nets for display logic,,,,,cs.CL,,"  This paper explores several extensions of proof nets for the Lambek calculus
in order to handle the different connectives of display logic in a natural way.
The new proof net calculus handles some recent additions to the Lambek
vocabulary such as Galois connections and Grishin interactions. It concludes
with an exploration of the generative capacity of the Lambek-Grishin calculus,
presenting an embedding of lexicalized tree adjoining grammars into the
Lambek-Grishin calculus.
","[{'version': 'v1', 'created': 'Thu, 15 Nov 2007 15:39:48 GMT'}]",2007-11-16,"[['Moot', 'Richard', '', 'INRIA Futurs, Labri']]"
42,711.3197,Igor M. Suslov,"I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,
  Russia)","How to realize ""a sense of humour"" in computers ?","14 pages, 6 figures included",,,,cs.CL cs.AI q-bio.NC,,"  Computer model of a ""sense of humour"" suggested previously [arXiv:0711.2058,
0711.2061, 0711.2270] is raised to the level of a realistic algorithm.
","[{'version': 'v1', 'created': 'Tue, 20 Nov 2007 19:57:23 GMT'}]",2007-11-27,"[['Suslov', 'I. M.', '', 'P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia']]"
43,711.3412,Eric Laporte,"Ivan Berlocher, Hyun-Gue Huh (IGM-LabInfo), Eric Laporte
  (IGM-LabInfo), Jee-Sun Nam",Morphological annotation of Korean with Directly Maintainable Resources,,"Dans Proceedings of the Language Resource and Evaluation
  Consference (LREC) - Morphological annotation of Korean with Directly
  Maintainable Resources, Genoa : Italie (2006)",,,cs.CL,,"  This article describes an exclusively resource-based method of morphological
annotation of written Korean text. Korean is an agglutinative language. Our
annotator is designed to process text before the operation of a syntactic
parser. In its present state, it annotates one-stem words only. The output is a
graph of morphemes annotated with accurate linguistic information. The
granularity of the tagset is 3 to 5 times higher than usual tagsets. A
comparison with a reference annotated corpus showed that it achieves 89% recall
without any corpus training. The language resources used by the system are
lexicons of stems, transducers of suffixes and transducers of generation of
allomorphs. All can be easily updated, which allows users to control the
evolution of the performances of the system. It has been claimed that
morphological annotation of Korean text could only be performed by a
morphological analysis module accessing a lexicon of morphemes. We show that it
can also be performed directly with a lexicon of words and without applying
morphological rules at annotation time, which speeds up annotation to 1,210
word/s. The lexicon of words is obtained from the maintainable language
resources through a fully automated compilation process.
","[{'version': 'v1', 'created': 'Wed, 21 Nov 2007 16:47:57 GMT'}]",2007-11-22,"[['Berlocher', 'Ivan', '', 'IGM-LabInfo'], ['Huh', 'Hyun-Gue', '', 'IGM-LabInfo'], ['Laporte', 'Eric', '', 'IGM-LabInfo'], ['Nam', 'Jee-Sun', '']]"
44,711.3449,Eric Laporte,Eric Laporte (IGM-LabInfo),Lexicon management and standard formats,,"Archives of Control Sciences 15, 3 (2005) 329-340",,,cs.CL,,"  International standards for lexicon formats are in preparation. To a certain
extent, the proposed formats converge with prior results of standardization
projects. However, their adequacy for (i) lexicon management and (ii)
lexicon-driven applications have been little debated in the past, nor are they
as a part of the present standardization effort. We examine these issues. IGM
has developed XML formats compatible with the emerging international standards,
and we report experimental results on large-coverage lexica.
","[{'version': 'v1', 'created': 'Wed, 21 Nov 2007 20:34:08 GMT'}]",2007-11-22,"[['Laporte', 'Eric', '', 'IGM-LabInfo']]"
45,711.3452,Eric Laporte,Eric Laporte (IGM-LabInfo),In memoriam Maurice Gross,8 pages,"Archives of Control Sciences 15, 3 (2005) 257-278",,,cs.CL,,"  Maurice Gross (1934-2001) was both a great linguist and a pioneer in natural
language processing. This article is written in homage to his memory
","[{'version': 'v1', 'created': 'Wed, 21 Nov 2007 20:38:29 GMT'}]",2007-11-22,"[['Laporte', 'Eric', '', 'IGM-LabInfo']]"
46,711.3453,Eric Laporte,"Hyun-Gue Huh (IGM-LabInfo), Eric Laporte (IGM-LabInfo)",A resource-based Korean morphological annotation system,6 pages,"Dans Proceedings of the International Joint Conference on Natural
  Language Processing (IJCNLP) - A resource-based Korean morphological
  annotation system, Jeju : Cor\'ee, R\'epublique de (2005)",,,cs.CL,,"  We describe a resource-based method of morphological annotation of written
Korean text. Korean is an agglutinative language. The output of our system is a
graph of morphemes annotated with accurate linguistic information. The language
resources used by the system can be easily updated, which allows us-ers to
control the evolution of the per-formances of the system. We show that
morphological annotation of Korean text can be performed directly with a
lexicon of words and without morpho-logical rules.
","[{'version': 'v1', 'created': 'Wed, 21 Nov 2007 20:41:59 GMT'}]",2007-11-22,"[['Huh', 'Hyun-Gue', '', 'IGM-LabInfo'], ['Laporte', 'Eric', '', 'IGM-LabInfo']]"
47,711.3454,Eric Laporte,"Eric Laporte (IGM-LabInfo), S\'ebastien Paumier (IGM-LabInfo)",Graphes param\'etr\'es et outils de lexicalisation,,"Dans Verbum ex machina. Proceedings of TALN - Graphes
  param\'etr\'es et outils de lexicalisation, Louvain : Belgique (2006)",,,cs.CL,,"  Shifting to a lexicalized grammar reduces the number of parsing errors and
improves application results. However, such an operation affects a syntactic
parser in all its aspects. One of our research objectives is to design a
realistic model for grammar lexicalization. We carried out experiments for
which we used a grammar with a very simple content and formalism, and a very
informative syntactic lexicon, the lexicon-grammar of French elaborated by the
LADL. Lexicalization was performed by applying the parameterized-graph
approach. Our results tend to show that most information in the lexicon-grammar
can be transferred into a grammar and exploited successfully for the syntactic
parsing of sentences.
","[{'version': 'v1', 'created': 'Wed, 21 Nov 2007 20:44:04 GMT'}]",2007-11-22,"[['Laporte', 'Eric', '', 'IGM-LabInfo'], ['Paumier', 'Sébastien', '', 'IGM-LabInfo']]"
48,711.3457,Eric Laporte,Eric Laporte (IGM-LabInfo),Evaluation of a Grammar of French Determiners,10 pages,"Dans Annals of the 27th Congress of the Brazilian Society of
  Computation - Evaluation of a Grammar of French Determiners, Rio de Janeiro :
  Br\'esil (2007)",,,cs.CL,,"  Existing syntactic grammars of natural languages, even with a far from
complete coverage, are complex objects. Assessments of the quality of parts of
such grammars are useful for the validation of their construction. We evaluated
the quality of a grammar of French determiners that takes the form of a
recursive transition network. The result of the application of this local
grammar gives deeper syntactic information than chunking or information
available in treebanks. We performed the evaluation by comparison with a corpus
independently annotated with information on determiners. We obtained 86%
precision and 92% recall on text not tagged for parts of speech.
","[{'version': 'v1', 'created': 'Wed, 21 Nov 2007 20:49:21 GMT'}]",2007-11-22,"[['Laporte', 'Eric', '', 'IGM-LabInfo']]"
49,711.3605,Eric Laporte,"Eric Laporte (IGM-LabInfo), Christian Lecl\`ere (IGM-LabInfo), Maria
  Carmelita P. Dias",Very strict selectional restrictions,,"Dans Proceedings - Very strict selectional restrictions. A
  Comparison between Portuguese and French, Itatiaia : Br\'esil (2006)",,,cs.CL,,"  We discuss the characteristics and behaviour of two parallel classes of verbs
in two Romance languages, French and Portuguese. Examples of these verbs are
Port. abater [gado] and Fr. abattre [b\'etail], both meaning ""slaughter
[cattle]"". In both languages, the definition of the class of verbs includes
several features: - They have only one essential complement, which is a direct
object. - The nominal distribution of the complement is very limited, i.e., few
nouns can be selected as head nouns of the complement. However, this selection
is not restricted to a single noun, as would be the case for verbal idioms such
as Fr. monter la garde ""mount guard"". - We excluded from the class
constructions which are reductions of more complex constructions, e.g. Port.
afinar [instrumento] com ""tune [instrument] with"".
","[{'version': 'v1', 'created': 'Thu, 22 Nov 2007 15:54:31 GMT'}]",2007-11-26,"[['Laporte', 'Eric', '', 'IGM-LabInfo'], ['Leclère', 'Christian', '', 'IGM-LabInfo'], ['Dias', 'Maria Carmelita P.', '']]"
50,711.3691,Eric Laporte,"Olivier Blanc (IGM-LabInfo), Matthieu Constant (IGM-LabInfo), Eric
  Laporte (IGM-LabInfo)","Outilex, plate-forme logicielle de traitement de textes \'ecrits",,"Dans Verbum ex machina. Proceedings of TALN - Outilex, plate-forme
  logicielle de traitement de textes \'ecrits, Louvain : Belgique (2006)",,,cs.CL,,"  The Outilex software platform, which will be made available to research,
development and industry, comprises software components implementing all the
fundamental operations of written text processing: processing without lexicons,
exploitation of lexicons and grammars, language resource management. All data
are structured in XML formats, and also in more compact formats, either
readable or binary, whenever necessary; the required format converters are
included in the platform; the grammar formats allow for combining statistical
approaches with resource-based approaches. Manually constructed lexicons for
French and English, originating from the LADL, and of substantial coverage,
will be distributed with the platform under LGPL-LR license.
","[{'version': 'v1', 'created': 'Fri, 23 Nov 2007 09:45:13 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Nov 2007 10:22:14 GMT'}]",2007-11-27,"[['Blanc', 'Olivier', '', 'IGM-LabInfo'], ['Constant', 'Matthieu', '', 'IGM-LabInfo'], ['Laporte', 'Eric', '', 'IGM-LabInfo']]"
51,711.3726,Stergos Afantenos,Michael Zock and Stergos D. Afantenos,Let's get the student into the driver's seat,6 pages,"The Seventh International Symposium on Natural Language Processing
  (SNLP 2007). Chonburi, Thailand",,,cs.CL,,"  Speaking a language and achieving proficiency in another one is a highly
complex process which requires the acquisition of various kinds of knowledge
and skills, like the learning of words, rules and patterns and their connection
to communicative goals (intentions), the usual starting point. To help the
learner to acquire these skills we propose an enhanced, electronic version of
an age old method: pattern drills (henceforth PDs). While being highly regarded
in the fifties, PDs have become unpopular since then, partially because of
their lack of grounding (natural context) and rigidity. Despite these
shortcomings we do believe in the virtues of this approach, at least with
regard to the acquisition of basic linguistic reflexes or skills (automatisms),
necessary to survive in the new language. Of course, the method needs
improvement, and we will show here how this can be achieved. Unlike tapes or
books, computers are open media, allowing for dynamic changes, taking users'
performances and preferences into account. Building an electronic version of
PDs amounts to building an open resource, accomodatable to the users' ever
changing needs.
","[{'version': 'v1', 'created': 'Fri, 23 Nov 2007 13:44:55 GMT'}]",2007-11-26,"[['Zock', 'Michael', ''], ['Afantenos', 'Stergos D.', '']]"
52,711.4475,{\L}ukasz D{\ke}bowski,{\L}ukasz D\k{e}bowski,Valence extraction using EM selection and co-occurrence matrices,"24 pages, 3 tables","Language Resources and Evaluation 43:301-327, 2009",10.1007/s10579-009-9100-5,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper discusses two new procedures for extracting verb valences from raw
texts, with an application to the Polish language. The first novel technique,
the EM selection algorithm, performs unsupervised disambiguation of valence
frame forests, obtained by applying a non-probabilistic deep grammar parser and
some post-processing to the text. The second new idea concerns filtering of
incorrect frames detected in the parsed text and is motivated by an observation
that verbs which take similar arguments tend to have similar frames. This
phenomenon is described in terms of newly introduced co-occurrence matrices.
Using co-occurrence matrices, we split filtering into two steps. The list of
valid arguments is first determined for each verb, whereas the pattern
according to which the arguments are combined into frames is computed in the
following stage. Our best extracted dictionary reaches an $F$-score of 45%,
compared to an $F$-score of 39% for the standard frame-based BHT filtering.
","[{'version': 'v1', 'created': 'Wed, 28 Nov 2007 12:16:08 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Dec 2007 12:53:25 GMT'}, {'version': 'v3', 'created': 'Fri, 11 Jul 2008 13:15:45 GMT'}, {'version': 'v4', 'created': 'Wed, 10 Dec 2008 19:14:24 GMT'}, {'version': 'v5', 'created': 'Wed, 29 Jul 2009 12:12:37 GMT'}, {'version': 'v6', 'created': 'Fri, 27 Nov 2009 17:53:24 GMT'}]",2020-03-11,"[['Dębowski', 'Łukasz', '']]"
53,712.1529,W Saba,Walid S. Saba,Ontology and Formal Semantics - Integration Overdue,,,,,cs.AI cs.CL,,"  In this note we suggest that difficulties encountered in natural language
semantics are, for the most part, due to the use of mere symbol manipulation
systems that are devoid of any content. In such systems, where there is hardly
any link with our common-sense view of the world, and it is quite difficult to
envision how one can formally account for the considerable amount of content
that is often implicit, but almost never explicitly stated in our everyday
discourse. The solution, in our opinion, is a compositional semantics grounded
in an ontology that reflects our commonsense view of the world and the way we
talk about it in ordinary language. In the compositional logic we envision
there are ontological (or first-intension) concepts, and logical (or
second-intension) concepts, and where the ontological concepts include not only
Davidsonian events, but other abstract objects as well (e.g., states,
processes, properties, activities, attributes, etc.) It will be demonstrated
here that in such a framework, a number of challenges in the semantics of
natural language (e.g., metonymy, intensionality, metaphor, etc.) can be
properly and uniformly addressed.
","[{'version': 'v1', 'created': 'Sat, 1 Dec 2007 14:27:12 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Dec 2007 20:25:26 GMT'}]",2007-12-13,"[['Saba', 'Walid S.', '']]"
54,712.3298,Bryan Gibson,"Dragomir Radev, Mark Hodges, Anthony Fader, Mark Joseph, Joshua
  Gerrish, Mark Schaller, Jonathan dePeri, Bryan Gibson",CLAIRLIB Documentation v1.03,"for download and additional information, please see
  http://www.clairlib.org",,,CSE-TR-536-07,cs.IR cs.CL,,"  The Clair library is intended to simplify a number of generic tasks in
Natural Language Processing (NLP), Information Retrieval (IR), and Network
Analysis. Its architecture also allows for external software to be plugged in
with very little effort. Functionality native to Clairlib includes
Tokenization, Summarization, LexRank, Biased LexRank, Document Clustering,
Document Indexing, PageRank, Biased PageRank, Web Graph Analysis, Network
Generation, Power Law Distribution Analysis, Network Analysis (clustering
coefficient, degree distribution plotting, average shortest path, diameter,
triangles, shortest path matrices, connected components), Cosine Similarity,
Random Walks on Graphs, Statistics (distributions, tests), Tf, Idf, Community
Finding.
","[{'version': 'v1', 'created': 'Wed, 19 Dec 2007 22:20:40 GMT'}]",2007-12-21,"[['Radev', 'Dragomir', ''], ['Hodges', 'Mark', ''], ['Fader', 'Anthony', ''], ['Joseph', 'Mark', ''], ['Gerrish', 'Joshua', ''], ['Schaller', 'Mark', ''], ['dePeri', 'Jonathan', ''], ['Gibson', 'Bryan', '']]"
55,712.3705,Tuomo Kakkonen,Tuomo Kakkonen,Framework and Resources for Natural Language Parser Evaluation,PhD dissertation. 264 pages,,,"University of Joensuu, Computer Science Dissertations 19",cs.CL,,"  Because of the wide variety of contemporary practices used in the automatic
syntactic parsing of natural languages, it has become necessary to analyze and
evaluate the strengths and weaknesses of different approaches. This research is
all the more necessary because there are currently no genre- and
domain-independent parsers that are able to analyze unrestricted text with 100%
preciseness (I use this term to refer to the correctness of analyses assigned
by a parser). All these factors create a need for methods and resources that
can be used to evaluate and compare parsing systems. This research describes:
(1) A theoretical analysis of current achievements in parsing and parser
evaluation. (2) A framework (called FEPa) that can be used to carry out
practical parser evaluations and comparisons. (3) A set of new evaluation
resources: FiEval is a Finnish treebank under construction, and MGTS and RobSet
are parser evaluation resources in English. (4) The results of experiments in
which the developed evaluation framework and the two resources for English were
used for evaluating a set of selected parsers.
","[{'version': 'v1', 'created': 'Fri, 21 Dec 2007 08:55:17 GMT'}]",2007-12-24,"[['Kakkonen', 'Tuomo', '']]"
56,801.0253,William Bialek,Greg J. Stephens and William Bialek,Toward a statistical mechanics of four letter words,,,10.1103/PhysRevE.81.066119,,q-bio.NC cs.CL physics.data-an physics.soc-ph,,"  We consider words as a network of interacting letters, and approximate the
probability distribution of states taken on by this network. Despite the
intuition that the rules of English spelling are highly combinatorial (and
arbitrary), we find that maximum entropy models consistent with pairwise
correlations among letters provide a surprisingly good approximation to the
full statistics of four letter words, capturing ~92% of the multi-information
among letters and even ""discovering"" real words that were not represented in
the data from which the pairwise correlations were estimated. The maximum
entropy model defines an energy landscape on the space of possible words, and
local minima in this landscape account for nearly two-thirds of words used in
written English.
","[{'version': 'v1', 'created': 'Mon, 31 Dec 2007 23:51:51 GMT'}]",2013-05-29,"[['Stephens', 'Greg J.', ''], ['Bialek', 'William', '']]"
57,801.1179,Bernard Jacquemin,"Bernard Jacquemin (ISC, UMR 7044, GERIICO), Sabine Ploux (ISC)",Corpus sp{\'e}cialis{\'e} et ressource de sp{\'e}cialit{\'e},"16 pages, in French","Appears in Fran\c{c}ois Maniez; Pascaline Dury; Nathalie Arlin;
  Claire Rougemont. Corpus et dictionnaires de langues de sp{\'e}cialit{\'e},
  Presses Universitaires de Granoble, pp.197-212, 2008",,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ""Semantic Atlas"" is a mathematic and statistic model to visualise word senses
according to relations between words. The model, that has been applied to
proximity relations from a corpus, has shown its ability to distinguish word
senses as the corpus' contributors comprehend them. We propose to use the model
and a specialised corpus in order to create automatically a specialised
dictionary relative to the corpus' domain. A morpho-syntactic analysis
performed on the corpus makes it possible to create the dictionary from
syntactic relations between lexical units. The semantic resource can be used to
navigate semantically - and not only lexically - through the corpus, to create
classical dictionaries or for diachronic studies of the language.
","[{'version': 'v1', 'created': 'Tue, 8 Jan 2008 08:21:26 GMT'}, {'version': 'v2', 'created': 'Fri, 19 Jun 2015 12:22:39 GMT'}]",2015-06-22,"[['Jacquemin', 'Bernard', '', 'ISC, UMR 7044, GERIICO'], ['Ploux', 'Sabine', '', 'ISC']]"
58,801.1415,Dietrich Stauffer,S. Wichmann,The emerging field of language dynamics,,,,,cs.CL physics.soc-ph,,"  A simple review by a linguist, citing many articles by physicists:
Quantitative methods, agent-based computer simulations, language dynamics,
language typology, historical linguistics
","[{'version': 'v1', 'created': 'Wed, 9 Jan 2008 12:34:40 GMT'}]",2008-01-10,"[['Wichmann', 'S.', '']]"
59,801.1658,Adam Lipowski,"Adam Lipowski, Dorota Lipowska","Computational approach to the emergence and evolution of language -
  evolutionary naming game model","paper withdrawn, much revised version is under preparation",,,,physics.soc-ph cs.CL cs.MA,,"  Computational modelling with multi-agent systems is becoming an important
technique of studying language evolution. We present a brief introduction into
this rapidly developing field, as well as our own contributions that include an
analysis of the evolutionary naming-game model. In this model communicating
agents, that try to establish a common vocabulary, are equipped with an
evolutionarily selected learning ability. Such a coupling of biological and
linguistic ingredients results in an abrupt transition: upon a small change of
the model control parameter a poorly communicating group of linguistically
unskilled agents transforms into almost perfectly communicating group with
large learning abilities. Genetic imprinting of the learning abilities proceeds
via Baldwin effect: initially unskilled communicating agents learn a language
and that creates a niche in which there is an evolutionary pressure for the
increase of learning ability. Under the assumption that communication intensity
increases continuously with finite speed, the transition is split into several
transition-like changes. It shows that the speed of cultural changes, that sets
an additional characteristic timescale, might be yet another factor affecting
the evolution of language. In our opinion, this model shows that linguistic and
biological processes have a strong influence on each other and this effect
certainly has contributed to an explosive development of our species.
","[{'version': 'v1', 'created': 'Thu, 10 Jan 2008 19:45:25 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Jan 2008 23:45:42 GMT'}, {'version': 'v3', 'created': 'Sat, 21 Aug 2010 21:14:21 GMT'}]",2010-08-24,"[['Lipowski', 'Adam', ''], ['Lipowska', 'Dorota', '']]"
60,801.251,Marcel Ausloos,J. Gillet and M. Ausloos,"A Comparison of natural (english) and artificial (esperanto) languages.
  A Multifractal method based analysis","7 pages, 4 double figures, 45 references",,,,cs.CL physics.data-an,,"  We present a comparison of two english texts, written by Lewis Carroll, one
(Alice in wonderland) and the other (Through a looking glass), the former
translated into esperanto, in order to observe whether natural and artificial
languages significantly differ from each other. We construct one dimensional
time series like signals using either word lengths or word frequencies. We use
the multifractal ideas for sorting out correlations in the writings. In order
to check the robustness of the methods we also write the corresponding shuffled
texts. We compare characteristic functions and e.g. observe marked differences
in the (far from parabolic) f(alpha) curves, differences which we attribute to
Tsallis non extensive statistical features in the ''frequency time series'' and
''length time series''. The esperanto text has more extreme vallues. A very
rough approximation consists in modeling the texts as a random Cantor set if
resulting from a binomial cascade of long and short words (or words and
blanks). This leads to parameters characterizing the text style, and most
likely in fine the author writings.
","[{'version': 'v1', 'created': 'Wed, 16 Jan 2008 14:07:33 GMT'}]",2008-01-17,"[['Gillet', 'J.', ''], ['Ausloos', 'M.', '']]"
61,801.3239,Andrij Rovenchak,"Solomiya Buk, Andrij Rovenchak","Online-concordance ""Perekhresni stezhky"" (""The Cross-Paths""), a novel by
  Ivan Franko",in Ukrainian,"Ivan Franko: Spirit, Science, Thought, Will (Proceedings of the
  International Scientific Congress dedicated to the 150th anniversary (Lviv,
  27 September -- 1 October 2006, Lviv University Press, Vol. 2, pp. 203-211,
  2010)",,,cs.CL cs.DL,,"  In the article, theoretical principles and practical realization for the
compilation of the concordance to ""Perekhresni stezhky"" (""The Cross-Paths""), a
novel by Ivan Franko, are described. Two forms for the context presentation are
proposed. The electronic version of this lexicographic work is available
online.
","[{'version': 'v1', 'created': 'Mon, 21 Jan 2008 17:41:57 GMT'}]",2014-01-17,"[['Buk', 'Solomiya', ''], ['Rovenchak', 'Andrij', '']]"
62,801.3817,Tuomo Kakkonen,Tuomo Kakkonen,"Robustness Evaluation of Two CCG, a PCFG and a Link Grammar Parsers",,"Proceedings of the 3rd Language & Technology Conference: Human
  Language Technologies as a Challenge for Computer Science and Linguistics.
  Poznan, Poland, 2007",,,cs.CL,,"  Robustness in a parser refers to an ability to deal with exceptional
phenomena. A parser is robust if it deals with phenomena outside its normal
range of inputs. This paper reports on a series of robustness evaluations of
state-of-the-art parsers in which we concentrated on one aspect of robustness:
its ability to parse sentences containing misspelled words. We propose two
measures for robustness evaluation based on a comparison of a parser's output
for grammatical input sentences and their noisy counterparts. In this paper, we
use these measures to compare the overall robustness of the four evaluated
parsers, and we present an analysis of the decline in parser performance with
increasing error levels. Our results indicate that performance typically
declines tens of percentage units when parsers are presented with texts
containing misspellings. When it was tested on our purpose-built test set of
443 sentences, the best parser in the experiment (C&C parser) was able to
return exactly the same parse tree for the grammatical and ungrammatical
sentences for 60.8%, 34.0% and 14.9% of the sentences with one, two or three
misspelled words respectively.
","[{'version': 'v1', 'created': 'Thu, 24 Jan 2008 18:41:01 GMT'}]",2008-01-25,"[['Kakkonen', 'Tuomo', '']]"
63,801.3864,Alberto Pepe Mr,Alberto Pepe and Johan Bollen,"Between conjecture and memento: shaping a collective emotional
  perception of the future","6 pages. AAAI Spring Symposium on Emotion, Personality, and Social
  Behavior",,,,cs.CL cs.GL,,"  Large scale surveys of public mood are costly and often impractical to
perform. However, the web is awash with material indicative of public mood such
as blogs, emails, and web queries. Inexpensive content analysis on such
extensive corpora can be used to assess public mood fluctuations. The work
presented here is concerned with the analysis of the public mood towards the
future. Using an extension of the Profile of Mood States questionnaire, we have
extracted mood indicators from 10,741 emails submitted in 2006 to futureme.org,
a web service that allows its users to send themselves emails to be delivered
at a later date. Our results indicate long-term optimism toward the future, but
medium-term apprehension and confusion.
","[{'version': 'v1', 'created': 'Fri, 25 Jan 2008 01:09:47 GMT'}]",2008-01-28,"[['Pepe', 'Alberto', ''], ['Bollen', 'Johan', '']]"
64,801.4716,Jean-Yves Antoine,"Tonio Wandmacher, Jean-Yves Antoine","Methods to integrate a language model with semantic information for a
  word prediction component",10 pages ; EMNLP'2007 Conference (Prague),,,,cs.CL,,"  Most current word prediction systems make use of n-gram language models (LM)
to estimate the probability of the following word in a phrase. In the past
years there have been many attempts to enrich such language models with further
syntactic or semantic information. We want to explore the predictive powers of
Latent Semantic Analysis (LSA), a method that has been shown to provide
reliable information on long-distance semantic dependencies between words in a
context. We present and evaluate here several methods that integrate LSA-based
information with a standard language model: a semantic cache, partial
reranking, and different forms of interpolation. We found that all methods show
significant improvements, compared to the 4-gram baseline, and most of them to
a simple cache model as well.
","[{'version': 'v1', 'created': 'Wed, 30 Jan 2008 17:10:24 GMT'}]",2008-01-31,"[['Wandmacher', 'Tonio', ''], ['Antoine', 'Jean-Yves', '']]"
65,801.4746,W Saba,Walid S. Saba,"Concerning Olga, the Beautiful Little Street Dancer (Adjectives as
  Higher-Order Polymorphic Functions)",6 pages,,,,cs.CL cs.LO,,"  In this paper we suggest a typed compositional seman-tics for nominal
compounds of the form [Adj Noun] that models adjectives as higher-order
polymorphic functions, and where types are assumed to represent concepts in an
ontology that reflects our commonsense view of the world and the way we talk
about it in or-dinary language. In addition to [Adj Noun] compounds our
proposal seems also to suggest a plausible explana-tion for well known
adjective ordering restrictions.
","[{'version': 'v1', 'created': 'Wed, 30 Jan 2008 19:40:45 GMT'}, {'version': 'v2', 'created': 'Thu, 31 Jan 2008 17:10:22 GMT'}, {'version': 'v3', 'created': 'Fri, 1 Feb 2008 01:34:55 GMT'}, {'version': 'v4', 'created': 'Mon, 4 Feb 2008 22:36:04 GMT'}, {'version': 'v5', 'created': 'Sun, 10 Feb 2008 08:26:02 GMT'}]",2008-02-10,"[['Saba', 'Walid S.', '']]"
66,802.2234,Christoph Schommer,"Christoph Schommer, Conny Uhde","Textual Fingerprinting with Texts from Parkin, Bassewitz, and Leander","11 pages, 4 Figures",,,,cs.CL cs.CR,,"  Current research in author profiling to discover a legal author's fingerprint
does not only follow examinations based on statistical parameters only but
include more and more dynamic methods that can learn and that react adaptable
to the specific behavior of an author. But the question on how to appropriately
represent a text is still one of the fundamental tasks, and the problem of
which attribute should be used to fingerprint the author's style is still not
exactly defined. In this work, we focus on linguistic selection of attributes
to fingerprint the style of the authors Parkin, Bassewitz and Leander. We use
texts of the genre Fairy Tale as it has a clear style and texts of a shorter
size with a straightforward story-line and a simple language.
","[{'version': 'v1', 'created': 'Fri, 15 Feb 2008 16:14:09 GMT'}]",2008-02-18,"[['Schommer', 'Christoph', ''], ['Uhde', 'Conny', '']]"
67,802.4112,Hanna E. Makaruk,"Hanna E. Makaruk, Robert Owczarek",Hubs in Languages: Scale Free Networks of Synonyms,,,,LA-UR-08-0084,physics.soc-ph cs.CL physics.data-an,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural languages are described in this paper in terms of networks of
synonyms: a word is identified with a node, and synonyms are connected by
undirected links. Our statistical analysis of the network of synonyms in Polish
language showed it is scale-free; similar to what is known for English. The
statistical properties of the networks are also similar. Thus, the statistical
aspects of the networks are good candidates for culture independent elements of
human language. We hypothesize that optimization for robustness and efficiency
is responsible for this universality. Despite the statistical similarity, there
is no one-to-one mapping between networks of these two languages. Although many
hubs in Polish are translated into similarly highly connected hubs in English,
there are also hubs specific to one of these languages only: a single word in
one language is equivalent to many different and disconnected words in the
other, in accordance with the Whorf hypothesis about language relativity.
Identifying language-specific hubs is vitally important for automatic
translation, and for understanding contextual, culturally related messages that
are frequently missed or twisted in a naive, literary translation.
","[{'version': 'v1', 'created': 'Thu, 28 Feb 2008 00:15:54 GMT'}]",2008-02-29,"[['Makaruk', 'Hanna E.', ''], ['Owczarek', 'Robert', '']]"
68,802.4198,Andrij Rovenchak,"Solomija Buk, J\'an Ma\v{c}utek, Andrij Rovenchak",Some properties of the Ukrainian writing system,17 pages,"Glottometrics 16, 63-79 (2008)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the grapheme-phoneme relation in Ukrainian and some properties
of the Ukrainian version of the Cyrillic alphabet.
","[{'version': 'v1', 'created': 'Thu, 28 Feb 2008 12:58:49 GMT'}]",2008-03-18,"[['Buk', 'Solomija', ''], ['Mačutek', 'Ján', ''], ['Rovenchak', 'Andrij', '']]"
69,802.4215,Marcel Ausloos,M. Ausloos,"Equilibrium (Zipf) and Dynamic (Grasseberg-Procaccia) method based
  analyses of human texts. A comparison of natural (english) and artificial
  (esperanto) languages","22 pages, 87 references, 5 tables, 8 figures",Physica A 387 (25) 6411-6420 (2008),10.1016/j.physa.2008.07.016,,physics.soc-ph cs.CL physics.data-an,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A comparison of two english texts from Lewis Carroll, one (Alice in
wonderland), also translated into esperanto, the other (Through a looking
glass) are discussed in order to observe whether natural and artificial
languages significantly differ from each other. One dimensional time series
like signals are constructed using only word frequencies (FTS) or word lengths
(LTS). The data is studied through (i) a Zipf method for sorting out
correlations in the FTS and (ii) a Grassberger-Procaccia (GP) technique based
method for finding correlations in LTS. Features are compared : different power
laws are observed with characteristic exponents for the ranking properties, and
the {\it phase space attractor dimensionality}. The Zipf exponent can take
values much less than unity ($ca.$ 0.50 or 0.30) depending on how a sentence is
defined. This non-universality is conjectured to be a measure of the author
$style$. Moreover the attractor dimension $r$ is a simple function of the so
called phase space dimension $n$, i.e., $r = n^{\lambda}$, with $\lambda =
0.79$. Such an exponent should also conjecture to be a measure of the author
$creativity$. However, even though there are quantitative differences between
the original english text and its esperanto translation, the qualitative
differences are very minutes, indicating in this case a translation relatively
well respecting, along our analysis lines, the content of the author writing.
","[{'version': 'v1', 'created': 'Thu, 28 Feb 2008 11:49:48 GMT'}]",2012-09-04,"[['Ausloos', 'M.', '']]"
70,802.4326,Jiyou Jia Dr.,Jiyou Jia,"The Generation of Textual Entailment with NLML in an Intelligent
  Dialogue system for Language Learning CSIEC",,,,,cs.CL cs.AI cs.CY,,"  This research report introduces the generation of textual entailment within
the project CSIEC (Computer Simulation in Educational Communication), an
interactive web-based human-computer dialogue system with natural language for
English instruction. The generation of textual entailment (GTE) is critical to
the further improvement of CSIEC project. Up to now we have found few
literatures related with GTE. Simulating the process that a human being learns
English as a foreign language we explore our naive approach to tackle the GTE
problem and its algorithm within the framework of CSIEC, i.e. rule annotation
in NLML, pattern recognition (matching), and entailment transformation. The
time and space complexity of our algorithm is tested with some entailment
examples. Further works include the rules annotation based on the English
textbooks and a GUI interface for normal users to edit the entailment rules.
","[{'version': 'v1', 'created': 'Fri, 29 Feb 2008 06:16:29 GMT'}]",2008-03-03,"[['Jia', 'Jiyou', '']]"
71,803.2856,Christoph Schommer,"T. Rothenberger, S. Oez, E. Tahirovic, C. Schommer","Figuring out Actors in Text Streams: Using Collocations to establish
  Incremental Mind-maps","10 pages, 3 Figures",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recognition, involvement, and description of main actors influences the
story line of the whole text. This is of higher importance as the text per se
represents a flow of words and expressions that once it is read it is lost. In
this respect, the understanding of a text and moreover on how the actor exactly
behaves is not only a major concern: as human beings try to store a given input
on short-term memory while associating diverse aspects and actors with
incidents, the following approach represents a virtual architecture, where
collocations are concerned and taken as the associative completion of the
actors' acting. Once that collocations are discovered, they become managed in
separated memory blocks broken down by the actors. As for human beings, the
memory blocks refer to associative mind-maps. We then present several priority
functions to represent the actual temporal situation inside a mind-map to
enable the user to reconstruct the recent events from the discovered temporal
results.
","[{'version': 'v1', 'created': 'Wed, 19 Mar 2008 18:00:19 GMT'}]",2008-12-18,"[['Rothenberger', 'T.', ''], ['Oez', 'S.', ''], ['Tahirovic', 'E.', ''], ['Schommer', 'C.', '']]"
72,804.0143,Benoit Lemaire,"Beno\^it Lemaire (TIMC), Guy Denhi\`ere (LPC)",Effects of High-Order Co-occurrences on Word Semantic Similarities,,"Current Psychology Letters - Behaviour, Brain and Cognition 18, 1
  (2006) 1",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A computational model of the construction of word meaning through exposure to
texts is built in order to simulate the effects of co-occurrence values on word
semantic similarities, paragraph by paragraph. Semantic similarity is here
viewed as association. It turns out that the similarity between two words W1
and W2 strongly increases with a co-occurrence, decreases with the occurrence
of W1 without W2 or W2 without W1, and slightly increases with high-order
co-occurrences. Therefore, operationalizing similarity as a frequency of
co-occurrence probably introduces a bias: first, there are cases in which there
is similarity without co-occurrence and, second, the frequency of co-occurrence
overestimates similarity.
","[{'version': 'v1', 'created': 'Tue, 1 Apr 2008 11:33:39 GMT'}]",2008-12-18,"[['Lemaire', 'Benoît', '', 'TIMC'], ['Denhière', 'Guy', '', 'LPC']]"
73,804.0317,Maurice H. T. Ling,"Maurice HT Ling, Christophe Lefevre, Kevin R. Nicholas","Parts-of-Speech Tagger Errors Do Not Necessarily Degrade Accuracy in
  Extracting Information from Biomedical Text",,"Ling, Maurice HT, Lefevre, Christophe, Nicholas, Kevin R. 2008.
  Parts-of-Speech Tagger Errors Do Not Necessarily Degrade Accuracy in
  Extracting Information from Biomedical Text. The Python Papers 3 (1): 65-80",,,cs.CL cs.IR,http://creativecommons.org/licenses/by-nc-sa/3.0/,"  A recent study reported development of Muscorian, a generic text processing
tool for extracting protein-protein interactions from text that achieved
comparable performance to biomedical-specific text processing tools. This
result was unexpected since potential errors from a series of text analysis
processes is likely to adversely affect the outcome of the entire process. Most
biomedical entity relationship extraction tools have used biomedical-specific
parts-of-speech (POS) tagger as errors in POS tagging and are likely to affect
subsequent semantic analysis of the text, such as shallow parsing. This study
aims to evaluate the parts-of-speech (POS) tagging accuracy and attempts to
explore whether a comparable performance is obtained when a generic POS tagger,
MontyTagger, was used in place of MedPost, a tagger trained in biomedical text.
Our results demonstrated that MontyTagger, Muscorian's POS tagger, has a POS
tagging accuracy of 83.1% when tested on biomedical text. Replacing MontyTagger
with MedPost did not result in a significant improvement in entity relationship
extraction from text; precision of 55.6% from MontyTagger versus 56.8% from
MedPost on directional relationships and 86.1% from MontyTagger compared to
81.8% from MedPost on nondirectional relationships. This is unexpected as the
potential for poor POS tagging by MontyTagger is likely to affect the outcome
of the information extraction. An analysis of POS tagging errors demonstrated
that 78.5% of tagging errors are being compensated by shallow parsing. Thus,
despite 83.1% tagging accuracy, MontyTagger has a functional tagging accuracy
of 94.6%.
","[{'version': 'v1', 'created': 'Wed, 2 Apr 2008 09:34:13 GMT'}]",2008-04-03,"[['Ling', 'Maurice HT', ''], ['Lefevre', 'Christophe', ''], ['Nicholas', 'Kevin R.', '']]"
74,804.1033,Christoph Schommer,"Sviatlana Danilava, Christoph Schommer","A Semi-Automatic Framework to Discover Epistemic Modalities in
  Scientific Articles","18 pages, 5 Figures",,,,cs.CL cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Documents in scientific newspapers are often marked by attitudes and opinions
of the author and/or other persons, who contribute with objective and
subjective statements and arguments as well. In this respect, the attitude is
often accomplished by a linguistic modality. As in languages like english,
french and german, the modality is expressed by special verbs like can, must,
may, etc. and the subjunctive mood, an occurrence of modalities often induces
that these verbs take over the role of modality. This is not correct as it is
proven that modality is the instrument of the whole sentence where both the
adverbs, modal particles, punctuation marks, and the intonation of a sentence
contribute. Often, a combination of all these instruments are necessary to
express a modality. In this work, we concern with the finding of modal verbs in
scientific texts as a pre-step towards the discovery of the attitude of an
author. Whereas the input will be an arbitrary text, the output consists of
zones representing modalities.
","[{'version': 'v1', 'created': 'Mon, 7 Apr 2008 14:13:27 GMT'}]",2008-12-18,"[['Danilava', 'Sviatlana', ''], ['Schommer', 'Christoph', '']]"
75,804.2354,Andrew Krizhanovsky A,"A. V. Smirnov, A. A. Krizhanovsky",Information filtering based on wiki index database,"9 pages, 1 table, 2 figures, 8th International FLINS Conference on
  Computational Intelligence in Decision and Control, Madrid, Spain, September
  21-24, 2008; v2: typo",,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we present a profile-based approach to information filtering by
an analysis of the content of text documents. The Wikipedia index database is
created and used to automatically generate the user profile from the user
document collection. The problem-oriented Wikipedia subcorpora are created
(using knowledge extracted from the user profile) for each topic of user
interests. The index databases of these subcorpora are applied to filtering
information flow (e.g., mails, news). Thus, the analyzed texts are classified
into several topics explicitly presented in the user profile. The paper
concentrates on the indexing part of the approach. The architecture of an
application implementing the Wikipedia indexing is described. The indexing
method is evaluated using the Russian and Simple English Wikipedia.
","[{'version': 'v1', 'created': 'Tue, 15 Apr 2008 11:05:59 GMT'}, {'version': 'v2', 'created': 'Thu, 8 May 2008 12:35:01 GMT'}]",2008-05-08,"[['Smirnov', 'A. V.', ''], ['Krizhanovsky', 'A. A.', '']]"
76,804.3269,Santiago Fern\'andez,"Santiago Fern\'andez, Alex Graves, Juergen Schmidhuber",Phoneme recognition in TIMIT with BLSTM-CTC,8 pages,,,IDSIA-04-08,cs.CL cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We compare the performance of a recurrent neural network with the best
results published so far on phoneme recognition in the TIMIT database. These
published results have been obtained with a combination of classifiers.
However, in this paper we apply a single recurrent neural network to the same
task. Our recurrent neural network attains an error rate of 24.6%. This result
is not significantly different from that obtained by the other best methods,
but they rely on a combination of classifiers for achieving comparable
performance.
","[{'version': 'v1', 'created': 'Mon, 21 Apr 2008 15:38:45 GMT'}]",2008-04-22,"[['Fernández', 'Santiago', ''], ['Graves', 'Alex', ''], ['Schmidhuber', 'Juergen', '']]"
77,804.3599,Lillian Lee,"Oren Kurland, Lillian Lee","Respect My Authority! HITS Without Hyperlinks, Utilizing Cluster-Based
  Language Models",,"Proceedings of SIGIR 2006, pp 83--90",,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an approach to improving the precision of an initial document
ranking wherein we utilize cluster information within a graph-based framework.
The main idea is to perform re-ranking based on centrality within bipartite
graphs of documents (on one side) and clusters (on the other side), on the
premise that these are mutually reinforcing entities. Links between entities
are created via consideration of language models induced from them.
  We find that our cluster-document graphs give rise to much better retrieval
performance than previously proposed document-only graphs do. For example,
authority-based re-ranking of documents via a HITS-style cluster-based approach
outperforms a previously-proposed PageRank-inspired algorithm applied to
solely-document graphs. Moreover, we also show that computing authority scores
for clusters constitutes an effective method for identifying clusters
containing a large percentage of relevant documents.
","[{'version': 'v1', 'created': 'Tue, 22 Apr 2008 20:02:14 GMT'}]",2008-04-24,"[['Kurland', 'Oren', ''], ['Lee', 'Lillian', '']]"
78,804.4584,Sylvain Schmitz,Sylvain Schmitz and Joseph Le Roux,Feature Unification in TAG Derivation Trees,"12 pages, 4 figures In TAG+9, Ninth International Workshop on Tree
  Adjoining Grammars and Related Formalisms, 2008","In TAG+9, Ninth International Workshop on Tree Adjoining Grammars
  and Related Formalisms, 2008",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The derivation trees of a tree adjoining grammar provide a first insight into
the sentence semantics, and are thus prime targets for generation systems. We
define a formalism, feature-based regular tree grammars, and a translation from
feature based tree adjoining grammars into this new formalism. The translation
preserves the derivation structures of the original grammar, and accounts for
feature unification.
","[{'version': 'v1', 'created': 'Tue, 29 Apr 2008 11:39:18 GMT'}]",2015-03-13,"[['Schmitz', 'Sylvain', ''], ['Roux', 'Joseph Le', '']]"
79,805.103,Martin Mann,"Stephane Zampelli, Martin Mann, Yves Deville and Rolf Backofen",Decomposition Techniques for Subgraph Matching,15 pages,,,INGI2008/03,cs.CC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the constraint programming framework, state-of-the-art static and dynamic
decomposition techniques are hard to apply to problems with complete initial
constraint graphs. For such problems, we propose a hybrid approach of these
techniques in the presence of global constraints. In particular, we solve the
subgraph isomorphism problem. Further we design specific heuristics for this
hard problem, exploiting its special structure to achieve decomposition. The
underlying idea is to precompute a static heuristic on a subset of its
constraint network, to follow this static ordering until a first problem
decomposition is available, and to switch afterwards to a fully propagated,
dynamically decomposing search. Experimental results show that, for sparse
graphs, our decomposition method solves more instances than dedicated,
state-of-the-art matching algorithms or standard constraint programming
approaches.
","[{'version': 'v1', 'created': 'Wed, 7 May 2008 17:41:47 GMT'}]",2008-12-18,"[['Zampelli', 'Stephane', ''], ['Mann', 'Martin', ''], ['Deville', 'Yves', ''], ['Backofen', 'Rolf', '']]"
80,805.2303,Richard Moot,"Richard Moot (LaBRI, Inria Futurs)",Graph Algorithms for Improving Type-Logical Proof Search,,"Dans Categorial grammars - an efficient tool for natural language
  processing - June 2004 - Categorial grammars - an efficient tool for natural
  language processing, Montpellier : France (2004)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Proof nets are a graph theoretical representation of proofs in various
fragments of type-logical grammar. In spite of this basis in graph theory,
there has been relatively little attention to the use of graph theoretic
algorithms for type-logical proof search. In this paper we will look at several
ways in which standard graph theoretic algorithms can be used to restrict the
search space. In particular, we will provide an O(n4) algorithm for selecting
an optimal axiom link at any stage in the proof search as well as a O(kn3)
algorithm for selecting the k best proof candidates.
","[{'version': 'v1', 'created': 'Thu, 15 May 2008 13:30:08 GMT'}]",2008-12-18,"[['Moot', 'Richard', '', 'LaBRI, Inria Futurs']]"
81,805.2537,Patrick Henry,"Patrick Henry, Christian Bassac (LaBRI)",A toolkit for a generative lexicon,poster - 6 pages,"Dans A toolkit for a Generative Lexicon - Fourth International
  Workshop on Generative Approaches to the Lexicon, PARIS : France (2007)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we describe the conception of a software toolkit designed for
the construction, maintenance and collaborative use of a Generative Lexicon. In
order to ease its portability and spreading use, this tool was built with free
and open source products. We eventually tested the toolkit and showed it
filters the adequate form of anaphoric reference to the modifier in endocentric
compounds.
","[{'version': 'v1', 'created': 'Fri, 16 May 2008 13:58:44 GMT'}]",2008-12-18,"[['Henry', 'Patrick', '', 'LaBRI'], ['Bassac', 'Christian', '', 'LaBRI']]"
82,805.3366,Fabian Steeg,"Fabian Steeg, Christoph Benden, Paul O. Samuelsdorff","Computational Representation of Linguistic Structures using
  Domain-Specific Languages","12 pages, 9 figures; based on work presented at the 12th
  International Conference on Functional Grammar",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We describe a modular system for generating sentences from formal definitions
of underlying linguistic structures using domain-specific languages. The system
uses Java in general, Prolog for lexical entries and custom domain-specific
languages based on Functional Grammar and Functional Discourse Grammar
notation, implemented using the ANTLR parser generator. We show how linguistic
and technological parts can be brought together in a natural language
processing system and how domain-specific languages can be used as a tool for
consistent formal notation in linguistic description.
","[{'version': 'v1', 'created': 'Wed, 21 May 2008 23:44:06 GMT'}]",2008-05-23,"[['Steeg', 'Fabian', ''], ['Benden', 'Christoph', ''], ['Samuelsdorff', 'Paul O.', '']]"
83,805.341,Sylvain Pogodalla,Sylvain Pogodalla (INRIA Lorraine - LORIA),"Exploring a type-theoretic approach to accessibility constraint
  modelling",,Dans Journ\'ees S\'emantiques et Mod\'elisation (2008),,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The type-theoretic modelling of DRT that [degroote06] proposed features
continuations for the management of the context in which a clause has to be
interpreted. This approach, while keeping the standard definitions of
quantifier scope, translates the rules of the accessibility constraints of
discourse referents inside the semantic recipes. In this paper, we deal with
additional rules for these accessibility constraints. In particular in the case
of discourse referents introduced by proper nouns, that negation does not
block, and in the case of rhetorical relations that structure discourses. We
show how this continuation-based approach applies to those accessibility
constraints and how we can consider the parallel management of various
principles.
","[{'version': 'v1', 'created': 'Thu, 22 May 2008 08:48:28 GMT'}]",2008-12-18,"[['Pogodalla', 'Sylvain', '', 'INRIA Lorraine - LORIA']]"
84,805.4101,Sylvie Saget,"Sylvie Saget (IRISA), Marc Guyomard (IRISA)","Goal-oriented Dialog as a Collaborative Subordinated Activity involving
  Collective Acceptance",,"Dans Proceedings of the 10th Workshop on the Semantics and the
  Pragmatics of Dialogue (Brandial 2006) - 10th Workshop on the Semantics and
  the Pragmatics of Dialogue (Brandial 2006), Potsdam : Allemagne (2006)",,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modeling dialog as a collaborative activity consists notably in specifying
the content of the Conversational Common Ground and the kind of social mental
state involved. In previous work (Saget, 2006), we claim that Collective
Acceptance is the proper social attitude for modeling Conversational Common
Ground in the particular case of goal-oriented dialog. In this paper, a
formalization of Collective Acceptance is shown, besides elements in order to
integrate this attitude in a rational model of dialog are provided; and
finally, a model of referential acts as being part of a collaborative activity
is presented. The particular case of reference has been chosen in order to
exemplify our claims.
","[{'version': 'v1', 'created': 'Tue, 27 May 2008 12:16:12 GMT'}]",2008-12-18,"[['Saget', 'Sylvie', '', 'IRISA'], ['Guyomard', 'Marc', '', 'IRISA']]"
85,805.4369,Benoit Lemaire,"Guy Denhi\`ere (LPC), Beno\^it Lemaire (TIMC), C\'edrick Bellissens,
  Sandra Jhean",A semantic space for modeling children's semantic memory,,"The handbook of Latent Semantic Analysis, Lawrence Erlbaum
  Associates (Ed.) (2007) 143-165",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The goal of this paper is to present a model of children's semantic memory,
which is based on a corpus reproducing the kinds of texts children are exposed
to. After presenting the literature in the development of the semantic memory,
a preliminary French corpus of 3.2 million words is described. Similarities in
the resulting semantic space are compared to human data on four tests:
association norms, vocabulary test, semantic judgments and memory tasks. A
second corpus is described, which is composed of subcorpora corresponding to
various ages. This stratified corpus is intended as a basis for developmental
studies. Finally, two applications of these models of semantic memory are
presented: the first one aims at tracing the development of semantic
similarities paragraph by paragraph; the second one describes an implementation
of a model of text comprehension derived from the Construction-integration
model (Kintsch, 1988, 1998) and based on such models of semantic memory.
","[{'version': 'v1', 'created': 'Wed, 28 May 2008 14:56:18 GMT'}]",2008-12-18,"[['Denhière', 'Guy', '', 'LPC'], ['Lemaire', 'Benoît', '', 'TIMC'], ['Bellissens', 'Cédrick', ''], ['Jhean', 'Sandra', '']]"
86,805.4521,Doina Tatar,Doina Tatar and Militon Frentiu,Textual Entailment Recognizing by Theorem Proving Approach,10 pages,"Studia Univ.Babes-Bolyai, Informatica, Vol.LI, Number 2, 2006",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we present two original methods for recognizing textual
inference. First one is a modified resolution method such that some linguistic
considerations are introduced in the unification of two atoms. The approach is
possible due to the recent methods of transforming texts in logic formulas.
Second one is based on semantic relations in text, as presented in WordNet.
Some similarities between these two methods are remarked.
","[{'version': 'v1', 'created': 'Thu, 29 May 2008 11:53:39 GMT'}]",2008-05-30,"[['Tatar', 'Doina', ''], ['Frentiu', 'Militon', '']]"
87,805.4722,Bernard Jacquemin,"Bernard Jacquemin (LIMSI), Aur\'elien Lauf (LIMSI), C\'eline Poudat
  (LTCI), Martine Hurault-Plantet (LIMSI), Nicolas Auray (LTCI)",La fiabilit\'e des informations sur le web,8 pp,"Dans Actes de la Conf\'erence en Recherche d'Information et
  Applications CORIA 2008 - Conf\'erence en Recherche d'Information et
  Applications 2008, Tr\'egastel : France (2008)",,,cs.IR cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Online IR tools have to take into account new phenomena linked to the
appearance of blogs, wiki and other collaborative publications. Among these
collaborative sites, Wikipedia represents a crucial source of information.
However, the quality of this information has been recently questionned. A
better knowledge of the contributors' behaviors should help users navigate
through information whose quality may vary from one source to another. In order
to explore this idea, we present an analysis of the role of different types of
contributors in the control of the publication of conflictual articles.
","[{'version': 'v1', 'created': 'Fri, 30 May 2008 10:45:42 GMT'}]",2008-12-18,"[['Jacquemin', 'Bernard', '', 'LIMSI'], ['Lauf', 'Aurélien', '', 'LIMSI'], ['Poudat', 'Céline', '', 'LTCI'], ['Hurault-Plantet', 'Martine', '', 'LIMSI'], ['Auray', 'Nicolas', '', 'LTCI']]"
88,805.4754,Bernard Jacquemin,"Bernard Jacquemin (LIMSI), Aur\'elien Lauf (LIMSI), C\'eline Poudat
  (LTCI), Martine Hurault-Plantet (LIMSI), Nicolas Auray (LTCI)",Managing conflicts between users in Wikipedia,12 pp,"Dans BIS 2008 Workshop proceedings - 11th Conference on Business
  Information Systems (BIS 2008), Social Aspects of the Web Workshop (SAW
  2008), Innsbruck : Autriche (2008)",,,cs.IR cs.CL cs.CY cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Wikipedia is nowadays a widely used encyclopedia, and one of the most visible
sites on the Internet. Its strong principle of collaborative work and free
editing sometimes generates disputes due to disagreements between users. In
this article we study how the wikipedian community resolves the conflicts and
which roles do wikipedian choose in this process. We observed the users
behavior both in the article talk pages, and in the Arbitration Committee pages
specifically dedicated to serious disputes. We first set up a users typology
according to their involvement in conflicts and their publishing and management
activity in the encyclopedia. We then used those user types to describe users
behavior in contributing to articles that are tagged by the wikipedian
community as being in conflict with the official guidelines of Wikipedia, or
conversely as being well featured.
","[{'version': 'v1', 'created': 'Fri, 30 May 2008 13:20:42 GMT'}]",2008-12-18,"[['Jacquemin', 'Bernard', '', 'LIMSI'], ['Lauf', 'Aurélien', '', 'LIMSI'], ['Poudat', 'Céline', '', 'LTCI'], ['Hurault-Plantet', 'Martine', '', 'LIMSI'], ['Auray', 'Nicolas', '', 'LTCI']]"
89,806.2581,Doina Tatar,"Doina Tatar, Gabriela Serban, Andreea Mihis, Mihaiela Lupea, Dana
  Lupsa and Militon Frentiu",A chain dictionary method for Word Sense Disambiguation and applications,"8 pages, 5 figures","Studia Universitatis Babes-Bolyai, Special Issue, KEPT 2007,
  Knowledge Engineering: Principles and Technologies, Cluj-Napoca, June 6-8,
  2007, pp 33-40,",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A large class of unsupervised algorithms for Word Sense Disambiguation (WSD)
is that of dictionary-based methods. Various algorithms have as the root Lesk's
algorithm, which exploits the sense definitions in the dictionary directly. Our
approach uses the lexical base WordNet for a new algorithm originated in
Lesk's, namely ""chain algorithm for disambiguation of all words"", CHAD. We show
how translation from a language into another one and also text entailment
verification could be accomplished by this disambiguation.
","[{'version': 'v1', 'created': 'Mon, 16 Jun 2008 13:48:55 GMT'}]",2008-12-18,"[['Tatar', 'Doina', ''], ['Serban', 'Gabriela', ''], ['Mihis', 'Andreea', ''], ['Lupea', 'Mihaiela', ''], ['Lupsa', 'Dana', ''], ['Frentiu', 'Militon', '']]"
90,806.371,Stevan Harnad,"A. Blondin Masse, G. Chicoisne, Y. Gargouri, S. Harnad, O. Picard, O.
  Marcotte",How Is Meaning Grounded in Dictionary Definitions?,"8 pages, 3 figures, TextGraphs-3 Workshop at the 22nd International
  Conference on Computational Linguistics, Coling 2008, Manchester, 18-22
  August, 2008",,,,cs.CL cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Meaning cannot be based on dictionary definitions all the way down: at some
point the circularity of definitions must be broken in some way, by grounding
the meanings of certain words in sensorimotor categories learned from
experience or shaped by evolution. This is the ""symbol grounding problem."" We
introduce the concept of a reachable set -- a larger vocabulary whose meanings
can be learned from a smaller vocabulary through definition alone, as long as
the meanings of the smaller vocabulary are themselves already grounded. We
provide simple algorithms to compute reachable sets for any given dictionary.
","[{'version': 'v1', 'created': 'Mon, 23 Jun 2008 15:53:05 GMT'}, {'version': 'v2', 'created': 'Tue, 15 Jul 2008 01:59:09 GMT'}]",2008-07-15,"[['Masse', 'A. Blondin', ''], ['Chicoisne', 'G.', ''], ['Gargouri', 'Y.', ''], ['Harnad', 'S.', ''], ['Picard', 'O.', ''], ['Marcotte', 'O.', '']]"
91,806.3787,Ted Pedersen,"Ted Pedersen (University of Minnesota, Duluth)","Computational Approaches to Measuring the Similarity of Short Contexts :
  A Review of Applications and Methods",23 pages,"University of Minnesota Supercomputing Institute Research Report
  UMSI 2010/118, October 2010",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Measuring the similarity of short written contexts is a fundamental problem
in Natural Language Processing. This article provides a unifying framework by
which short context problems can be categorized both by their intended
application and proposed solution. The goal is to show that various problems
and methodologies that appear quite different on the surface are in fact very
closely related. The axes by which these categorizations are made include the
format of the contexts (headed versus headless), the way in which the contexts
are to be measured (first-order versus second-order similarity), and the
information used to represent the features in the contexts (micro versus macro
views). The unifying thread that binds together many short context applications
and methods is the fact that similarity decisions must be made between contexts
that share few (if any) words in common.
","[{'version': 'v1', 'created': 'Mon, 23 Jun 2008 23:27:20 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Oct 2010 19:08:13 GMT'}]",2010-10-19,"[['Pedersen', 'Ted', '', 'University of Minnesota, Duluth']]"
92,807.0311,Dmitry Lande,D.V. Lande and V.V. Zhygalo,About the creation of a parallel bilingual corpora of web-publications,3 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The algorithm of the creation texts parallel corpora was presented. The
algorithm is based on the use of ""key words"" in text documents, and on the
means of their automated translation. Key words were singled out by means of
using Russian and Ukrainian morphological dictionaries, as well as dictionaries
of the translation of nouns for the Russian and Ukrainianlanguages. Besides, to
calculate the weights of the terms in the documents, empiric-statistic rules
were used. The algorithm under consideration was realized in the form of a
program complex, integrated into the content-monitoring InfoStream system. As a
result, a parallel bilingual corpora of web-publications containing about 30
thousand documents, was created
","[{'version': 'v1', 'created': 'Wed, 2 Jul 2008 09:49:14 GMT'}]",2008-07-03,"[['Lande', 'D. V.', ''], ['Zhygalo', 'V. V.', '']]"
93,807.0565,Damian H. Zanette,Damian H. Zanette,"Music, Complexity, Information",,,,,physics.soc-ph cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  These are the preparatory notes for a Science & Music essay, ""Playing by
numbers"", appeared in Nature 453 (2008) 988-989.
","[{'version': 'v1', 'created': 'Thu, 3 Jul 2008 13:42:00 GMT'}]",2008-07-04,"[['Zanette', 'Damian H.', '']]"
94,807.156,Vahed Qazvinian,Vahed Qazvinian and Dragomir R. Radev,Scientific Paper Summarization Using Citation Summary Networks,,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by-nc-sa/3.0/,"  Quickly moving to a new area of research is painful for researchers due to
the vast amount of scientific literature in each field of study. One possible
way to overcome this problem is to summarize a scientific topic. In this paper,
we propose a model of summarizing a single article, which can be further used
to summarize an entire topic. Our model is based on analyzing others' viewpoint
of the target article's contributions and the study of its citation summary
network using a clustering approach.
","[{'version': 'v1', 'created': 'Thu, 10 Jul 2008 00:01:20 GMT'}]",2008-07-11,"[['Qazvinian', 'Vahed', ''], ['Radev', 'Dragomir R.', '']]"
95,807.3622,Yannick Parmentier,"Laura Kallmeyer (SFB 441), Timm Lichte (SFB 441), Wolfgang Maier (SFB
  441), Yannick Parmentier (INRIA Lorraine - LORIA), Johannes Dellert (SFB
  441), Kilian Evang (SFB 441)","TuLiPA: Towards a Multi-Formalism Parsing Environment for Grammar
  Engineering","Dans 2nd Workshop on Grammar Engineering Across Frameworks, GEAF 2008
  (2008)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present an open-source parsing environment (Tuebingen
Linguistic Parsing Architecture, TuLiPA) which uses Range Concatenation Grammar
(RCG) as a pivot formalism, thus opening the way to the parsing of several
mildly context-sensitive formalisms. This environment currently supports
tree-based grammars (namely Tree-Adjoining Grammars, TAG) and Multi-Component
Tree-Adjoining Grammars with Tree Tuples (TT-MCTAG)) and allows computation not
only of syntactic structures, but also of the corresponding semantic
representations. It is used for the development of a tree-based grammar for
German.
","[{'version': 'v1', 'created': 'Wed, 23 Jul 2008 09:05:50 GMT'}]",2009-09-29,"[['Kallmeyer', 'Laura', '', 'SFB 441'], ['Lichte', 'Timm', '', 'SFB 441'], ['Maier', 'Wolfgang', '', 'SFB\n  441'], ['Parmentier', 'Yannick', '', 'INRIA Lorraine - LORIA'], ['Dellert', 'Johannes', '', 'SFB\n  441'], ['Evang', 'Kilian', '', 'SFB 441']]"
96,807.3845,Stefano Crespi Reghizzi,Stefano Crespi Reghizzi,Formal semantics of language and the Richard-Berry paradox,,,,,cs.CL cs.CC cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The classical logical antinomy known as Richard-Berry paradox is combined
with plausible assumptions about the size i.e. the descriptional complexity of
Turing machines formalizing certain sentences, to show that formalization of
language leads to contradiction.
","[{'version': 'v1', 'created': 'Thu, 24 Jul 2008 10:31:55 GMT'}]",2008-07-25,"[['Reghizzi', 'Stefano Crespi', '']]"
97,808.0521,Ian Pratt-Hartmann,Ian Pratt-Hartmann and Lawrence S. Moss,Logics for the Relational Syllogistic,,,,,cs.LO cs.CC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Aristotelian syllogistic cannot account for the validity of many
inferences involving relational facts. In this paper, we investigate the
prospects for providing a relational syllogistic. We identify several fragments
based on (a) whether negation is permitted on all nouns, including those in the
subject of a sentence; and (b) whether the subject noun phrase may contain a
relative clause. The logics we present are extensions of the classical
syllogistic, and we pay special attention to the question of whether reductio
ad absurdum is needed. Thus our main goal is to derive results on the existence
(or non-existence) of syllogistic proof systems for relational fragments. We
also determine the computational complexity of all our fragments.
","[{'version': 'v1', 'created': 'Mon, 4 Aug 2008 22:26:38 GMT'}]",2008-08-06,"[['Pratt-Hartmann', 'Ian', ''], ['Moss', 'Lawrence S.', '']]"
98,808.1211,W Saba,Walid S. Saba,"Commonsense Knowledge, Ontology and Ordinary Language",To appear in Int. J. Reasoning-based Intelligent Systems,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Over two decades ago a ""quite revolution"" overwhelmingly replaced
knowledgebased approaches in natural language processing (NLP) by quantitative
(e.g., statistical, corpus-based, machine learning) methods. Although it is our
firm belief that purely quantitative approaches cannot be the only paradigm for
NLP, dissatisfaction with purely engineering approaches to the construction of
large knowledge bases for NLP are somewhat justified. In this paper we hope to
demonstrate that both trends are partly misguided and that the time has come to
enrich logical semantics with an ontological structure that reflects our
commonsense view of the world and the way we talk about in ordinary language.
In this paper it will be demonstrated that assuming such an ontological
structure a number of challenges in the semantics of natural language (e.g.,
metonymy, intensionality, copredication, nominal compounds, etc.) can be
properly and uniformly addressed.
","[{'version': 'v1', 'created': 'Fri, 8 Aug 2008 14:37:45 GMT'}]",2008-08-11,"[['Saba', 'Walid S.', '']]"
99,808.1753,Andrew Krizhanovsky A,A. A. Krizhanovsky,Index wiki database: design and experiments,"18 pages, 4 tables, 4 figures; FLINS'08, Corpus Linguistics'08,
  AIS/CAD'08; v2: table 3 changed",,,,cs.IR cs.CL,http://creativecommons.org/licenses/publicdomain/,"  With the fantastic growth of Internet usage, information search in documents
of a special type called a ""wiki page"" that is written using a simple markup
language, has become an important problem. This paper describes the software
architectural model for indexing wiki texts in three languages (Russian,
English, and German) and the interaction between the software components (GATE,
Lemmatizer, and Synarcher). The inverted file index database was designed using
visual tool DBDesigner. The rules for parsing Wikipedia texts are illustrated
by examples. Two index databases of Russian Wikipedia (RW) and Simple English
Wikipedia (SEW) are built and compared. The size of RW is by order of magnitude
higher than SEW (number of words, lexemes), though the growth rate of number of
pages in SEW was found to be 14% higher than in Russian, and the rate of
acquisition of new words in SEW lexicon was 7% higher during a period of five
months (from September 2007 to February 2008). The Zipf's law was tested with
both Russian and Simple Wikipedias. The entire source code of the indexing
software and the generated index databases are freely available under GPL (GNU
General Public License).
","[{'version': 'v1', 'created': 'Tue, 12 Aug 2008 23:47:21 GMT'}, {'version': 'v2', 'created': 'Tue, 23 Sep 2008 15:41:44 GMT'}]",2008-09-23,"[['Krizhanovsky', 'A. A.', '']]"
100,808.2904,Reginald Smith,Reginald D. Smith,Investigation of the Zipf-plot of the extinct Meroitic language,"10 pages, 2 figures","Glottometrics 15, 2007, 53-61",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The ancient and extinct language Meroitic is investigated using Zipf's Law.
In particular, since Meroitic is still undeciphered, the Zipf law analysis
allows us to assess the quality of current texts and possible avenues for
future investigation using statistical techniques.
","[{'version': 'v1', 'created': 'Thu, 21 Aug 2008 10:54:54 GMT'}]",2008-08-22,"[['Smith', 'Reginald D.', '']]"
101,808.3563,Stevan Harnad,Stevan Harnad,What It Feels Like To Hear Voices: Fond Memories of Julian Jaynes,16 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Julian Jaynes's profound humanitarian convictions not only prevented him from
going to war, but would have prevented him from ever kicking a dog. Yet
according to his theory, not only are language-less dogs unconscious, but so
too were the speaking/hearing Greeks in the Bicameral Era, when they heard
gods' voices telling them what to do rather than thinking for themselves. I
argue that to be conscious is to be able to feel, and that all mammals (and
probably lower vertebrates and invertebrates too) feel, hence are conscious.
Julian Jaynes's brilliant analysis of our concepts of consciousness
nevertheless keeps inspiring ever more inquiry and insights into the age-old
mind/body problem and its relation to cognition and language.
","[{'version': 'v1', 'created': 'Tue, 26 Aug 2008 18:17:44 GMT'}]",2009-09-29,"[['Harnad', 'Stevan', '']]"
102,808.3569,Stevan Harnad,"Itiel Dror, Stevan Harnad",Offloading Cognition onto Cognitive Technology,"To Appear in: Itiel E. Dror & Stevan Harnad (Eds) Cognition
  Distributed: How Cognitive Technology Extends Our Minds. Amsterdam: John
  Benjamins",,,,cs.MA cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ""Cognizing"" (e.g., thinking, understanding, and knowing) is a mental state.
Systems without mental states, such as cognitive technology, can sometimes
contribute to human cognition, but that does not make them cognizers. Cognizers
can offload some of their cognitive functions onto cognitive technology,
thereby extending their performance capacity beyond the limits of their own
brain power. Language itself is a form of cognitive technology that allows
cognizers to offload some of their cognitive functions onto the brains of other
cognizers. Language also extends cognizers' individual and joint performance
powers, distributing the load through interactive and collaborative cognition.
Reading, writing, print, telecommunications and computing further extend
cognizers' capacities. And now the web, with its network of cognizers, digital
databases and software agents, all accessible anytime, anywhere, has become our
'Cognitive Commons,' in which distributed cognizers and cognitive technology
can interoperate globally with a speed, scope and degree of interactivity
inconceivable through local individual cognition alone. And as with language,
the cognitive tool par excellence, such technological changes are not merely
instrumental and quantitative: they can have profound effects on how we think
and encode information, on how we communicate with one another, on our mental
states, and on our very nature.
","[{'version': 'v1', 'created': 'Tue, 26 Aug 2008 19:15:24 GMT'}, {'version': 'v2', 'created': 'Sat, 30 Aug 2008 22:50:46 GMT'}, {'version': 'v3', 'created': 'Mon, 1 Sep 2008 20:34:05 GMT'}]",2009-09-29,"[['Dror', 'Itiel', ''], ['Harnad', 'Stevan', '']]"
103,808.3616,Reginald Smith,Reginald D. Smith,Constructing word similarities in Meroitic as an aid to decipherment,"10 pages; 2 figures; to appear in British Museum studies in Ancient
  Egypt and Sudan","British Museum Studies in Ancient Egypt and Sudan, 12, 1-10 (2009)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Meroitic is the still undeciphered language of the ancient civilization of
Kush. Over the years, various techniques for decipherment such as finding a
bilingual text or cognates from modern or other ancient languages in the Sudan
and surrounding areas has not been successful. Using techniques borrowed from
information theory and natural language statistics, similar words are paired
and attempts are made to use currently defined words to extract at least
partial meaning from unknown words.
","[{'version': 'v1', 'created': 'Wed, 27 Aug 2008 02:02:40 GMT'}, {'version': 'v2', 'created': 'Mon, 8 Sep 2008 01:49:00 GMT'}, {'version': 'v3', 'created': 'Mon, 30 Mar 2009 11:53:07 GMT'}]",2009-08-24,"[['Smith', 'Reginald D.', '']]"
104,808.3889,Manuel Tomas Carrasco Benitez Mr.,M.T. Carrasco Benitez,Open architecture for multilingual parallel texts,"22 pages - for comments to the author and follow-ups go to
  http://dragoman.org/par",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/3.0/,"  Multilingual parallel texts (abbreviated to parallel texts) are linguistic
versions of the same content (""translations""); e.g., the Maastricht Treaty in
English and Spanish are parallel texts. This document is about creating an open
architecture for the whole Authoring, Translation and Publishing Chain
(ATP-chain) for the processing of parallel texts.
","[{'version': 'v1', 'created': 'Thu, 28 Aug 2008 11:59:34 GMT'}]",2008-08-29,"[['Benitez', 'M. T. Carrasco', '']]"
105,808.4122,Tomoyuki Yamakami,Tomoyuki Yamakami,Swapping Lemmas for Regular and Context-Free Languages,"Version 2: minor chages associated with typos; slight changes of
  title, abstract, and introduction (letter size, 13 pages, 4 figures)",,,,cs.CC cs.CL cs.FL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In formal language theory, one of the most fundamental tools, known as
pumping lemmas, is extremely useful for regular and context-free languages.
However, there are natural properties for which the pumping lemmas are of
little use. One of such examples concerns a notion of advice, which depends
only on the size of an underlying input. A standard pumping lemma encounters
difficulty in proving that a given language is not regular in the presence of
advice. We develop its substitution, called a swapping lemma for regular
languages, to demonstrate the non-regularity of a target language with advice.
For context-free languages, we also present a similar form of swapping lemma,
which serves as a technical tool to show that certain languages are not
context-free with advice.
","[{'version': 'v1', 'created': 'Fri, 29 Aug 2008 16:09:08 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Mar 2009 16:13:24 GMT'}]",2009-03-05,"[['Yamakami', 'Tomoyuki', '']]"
106,809.0103,Dmitrii Manin,Dmitrii Y. Manin,On the nature of long-range letter correlations in texts,"14 pages, 5 figures, unpublished",,,,cs.CL cs.IT math.IT,http://creativecommons.org/licenses/by-nc-sa/3.0/,"  The origin of long-range letter correlations in natural texts is studied
using random walk analysis and Jensen-Shannon divergence. It is concluded that
they result from slow variations in letter frequency distribution, which are a
consequence of slow variations in lexical composition within the text. These
correlations are preserved by random letter shuffling within a moving window.
As such, they do reflect structural properties of the text, but in a very
indirect manner.
","[{'version': 'v1', 'created': 'Sun, 31 Aug 2008 06:08:15 GMT'}]",2016-11-27,"[['Manin', 'Dmitrii Y.', '']]"
107,809.0124,Peter Turney,Peter D. Turney (National Research Council of Canada),"A Uniform Approach to Analogies, Synonyms, Antonyms, and Associations",related work available at http://purl.org/peter.turney/,"Proceedings of the 22nd International Conference on Computational
  Linguistics (Coling 2008), August 2008, Manchester, UK, Pages 905-912",,NRC 50398,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recognizing analogies, synonyms, antonyms, and associations appear to be four
distinct tasks, requiring distinct NLP algorithms. In the past, the four tasks
have been treated independently, using a wide variety of algorithms. These four
semantic classes, however, are a tiny sample of the full range of semantic
phenomena, and we cannot afford to create ad hoc algorithms for each semantic
phenomenon; we need to seek a unified approach. We propose to subsume a broad
range of phenomena under analogies. To limit the scope of this paper, we
restrict our attention to the subsumption of synonyms, antonyms, and
associations. We introduce a supervised corpus-based machine learning algorithm
for classifying analogous word pairs, and we show that it can solve
multiple-choice SAT analogy questions, TOEFL synonym questions, ESL
synonym-antonym questions, and similar-associated-both questions from cognitive
psychology.
","[{'version': 'v1', 'created': 'Sun, 31 Aug 2008 14:00:26 GMT'}]",2008-09-02,"[['Turney', 'Peter D.', '', 'National Research Council of Canada']]"
108,809.036,Aniello Murano,"Piero A. Bonatti, Carsten Lutz, Aniello Murano, Moshe Y. Vardi",The Complexity of Enriched Mu-Calculi,"A preliminary version of this paper appears in the Proceedings of the
  33rd International Colloquium on Automata, Languages and Programming (ICALP),
  2006. This paper has been selected for a special issue in LMCS","Logical Methods in Computer Science, Volume 4, Issue 3 (September
  22, 2008) lmcs:993",10.2168/LMCS-4(3:11)2008,,cs.LO cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The fully enriched &mu;-calculus is the extension of the propositional
&mu;-calculus with inverse programs, graded modalities, and nominals. While
satisfiability in several expressive fragments of the fully enriched
&mu;-calculus is known to be decidable and ExpTime-complete, it has recently
been proved that the full calculus is undecidable. In this paper, we study the
fragments of the fully enriched &mu;-calculus that are obtained by dropping at
least one of the additional constructs. We show that, in all fragments obtained
in this way, satisfiability is decidable and ExpTime-complete. Thus, we
identify a family of decidable logics that are maximal (and incomparable) in
expressive power. Our results are obtained by introducing two new automata
models, showing that their emptiness problems are ExpTime-complete, and then
reducing satisfiability in the relevant logics to these problems. The automata
models we introduce are two-way graded alternating parity automata over
infinite trees (2GAPTs) and fully enriched automata (FEAs) over infinite
forests. The former are a common generalization of two incomparable automata
models from the literature. The latter extend alternating automata in a similar
way as the fully enriched &mu;-calculus extends the standard &mu;-calculus.
","[{'version': 'v1', 'created': 'Tue, 2 Sep 2008 07:51:04 GMT'}, {'version': 'v2', 'created': 'Mon, 22 Sep 2008 19:10:39 GMT'}]",2015-07-01,"[['Bonatti', 'Piero A.', ''], ['Lutz', 'Carsten', ''], ['Murano', 'Aniello', ''], ['Vardi', 'Moshe Y.', '']]"
109,809.325,Andrey Kutuzov,Andrey Kutuzov,Using descriptive mark-up to formalize translation quality assessment,9 pages,"Published in Russian in 'Translation industry and information
  supply in international business activities: materials of international
  conference' - Perm, 2008, pp. 90-101",,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/3.0/,"  The paper deals with using descriptive mark-up to emphasize translation
mistakes. The author postulates the necessity to develop a standard and formal
XML-based way of describing translation mistakes. It is considered to be
important for achieving impersonal translation quality assessment. Marked-up
translations can be used in corpus translation studies; moreover, automatic
translation assessment based on marked-up mistakes is possible. The paper
concludes with setting up guidelines for further activity within the described
field.
","[{'version': 'v1', 'created': 'Thu, 18 Sep 2008 20:48:13 GMT'}]",2008-09-22,"[['Kutuzov', 'Andrey', '']]"
110,809.453,Olena Medelyan,"Olena Medelyan, David Milne, Catherine Legg and Ian H. Witten",Mining Meaning from Wikipedia,"An extensive survey of re-using information in Wikipedia in natural
  language processing, information retrieval and extraction and ontology
  building. Accepted for publication in International Journal of Human-Computer
  Studies",,,ISSN 1177-777X,cs.AI cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Wikipedia is a goldmine of information; not just for its many readers, but
also for the growing community of researchers who recognize it as a resource of
exceptional scale and utility. It represents a vast investment of manual effort
and judgment: a huge, constantly evolving tapestry of concepts and relations
that is being applied to a host of tasks.
  This article provides a comprehensive description of this work. It focuses on
research that extracts and makes use of the concepts, relations, facts and
descriptions found in Wikipedia, and organizes the work into four broad
categories: applying Wikipedia to natural language processing; using it to
facilitate information retrieval and information extraction; and as a resource
for ontology building. The article addresses how Wikipedia is being used as is,
how it is being improved and adapted, and how it is being combined with other
structures to create entirely new resources. We identify the research groups
and individuals involved, and how their work has developed in the last few
years. We provide a comprehensive list of the open-source software they have
produced.
","[{'version': 'v1', 'created': 'Fri, 26 Sep 2008 04:47:19 GMT'}, {'version': 'v2', 'created': 'Sun, 10 May 2009 01:51:15 GMT'}]",2009-05-10,"[['Medelyan', 'Olena', ''], ['Milne', 'David', ''], ['Legg', 'Catherine', ''], ['Witten', 'Ian H.', '']]"
111,810.02,Andrij Rovenchak,"Andrij Rovenchak, J\'an Ma\v{c}utek, Charles Riley",Distribution of complexities in the Vai script,13 pages,"Glottometrics 18, 1-12 (2009)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the paper, we analyze the distribution of complexities in the Vai script,
an indigenous syllabic writing system from Liberia. It is found that the
uniformity hypothesis for complexities fails for this script. The models using
Poisson distribution for the number of components and hyper-Poisson
distribution for connections provide good fits in the case of the Vai script.
","[{'version': 'v1', 'created': 'Wed, 1 Oct 2008 15:53:36 GMT'}]",2009-02-10,"[['Rovenchak', 'Andrij', ''], ['Mačutek', 'Ján', ''], ['Riley', 'Charles', '']]"
112,810.1199,Pascal Vaillant,Pascal Vaillant,"Une grammaire formelle du cr\'eole martiniquais pour la g\'en\'eration
  automatique","In French. 10 pages, 4 figures, LaTeX 2e using EPSF and custom
  package Taln2003.sty (JC/PZ, ATALA). Proceedings of the 10th annual
  French-speaking conference on Natural Language Processing: `Traitement
  Automatique des Langues Naturelles' (TALN 2003), Batz-sur-mer, France, 10-14
  June 2003","Actes de la 10eme conference annuelle sur le Traitement
  Automatique des Langues Naturelles (TALN 2003), p. 255-264. Batz-sur-mer,
  France, 10-14 juin 2003",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this article, some first elements of a computational modelling of the
grammar of the Martiniquese French Creole dialect are presented. The sources of
inspiration for the modelling is the functional description given by Damoiseau
(1984), and Pinalie's & Bernabe's (1999) grammar manual. Based on earlier works
in text generation (Vaillant, 1997), a unification grammar formalism, namely
Tree Adjoining Grammars (TAG), and a modelling of lexical functional categories
based on syntactic and semantic properties, are used to implement a grammar of
Martiniquese Creole which is used in a prototype of text generation system. One
of the main applications of the system could be its use as a tool software
supporting the task of learning Creole as a second language. -- Nous
pr\'esenterons dans cette communication les premiers travaux de mod\'elisation
informatique d'une grammaire de la langue cr\'eole martiniquaise, en nous
inspirant des descriptions fonctionnelles de Damoiseau (1984) ainsi que du
manuel de Pinalie & Bernab\'e (1999). Prenant appui sur des travaux
ant\'erieurs en g\'en\'eration de texte (Vaillant, 1997), nous utilisons un
formalisme de grammaires d'unification, les grammaires d'adjonction d'arbres
(TAG d'apr\`es l'acronyme anglais), ainsi qu'une mod\'elisation de cat\'egories
lexicales fonctionnelles \`a base syntaxico-s\'emantique, pour mettre en oeuvre
une grammaire du cr\'eole martiniquais utilisable dans une maquette de
syst\`eme de g\'en\'eration automatique. L'un des int\'er\^ets principaux de ce
syst\`eme pourrait \^etre son utilisation comme logiciel outil pour l'aide \`a
l'apprentissage du cr\'eole en tant que langue seconde.
","[{'version': 'v1', 'created': 'Tue, 7 Oct 2008 14:40:19 GMT'}]",2008-10-08,"[['Vaillant', 'Pascal', '']]"
113,810.1207,Pascal Vaillant,Pascal Vaillant,"A Layered Grammar Model: Using Tree-Adjoining Grammars to Build a Common
  Syntactic Kernel for Related Dialects","8 pages, 3 figures, 2 tables. LaTeX 2e using the coling08 style (and
  standard packages like epsf, amssymb, multirow, url...). Proceedings of the
  9th International Workshop on Tree Adjoining Grammars and Related Formalisms.
  Tuebingen, Baden-Wurttemberg, Germany, 6-8 June 2008","Proceedings of the Ninth International Workshop on Tree Adjoining
  Grammars and Related Formalisms (TAG+9 2008), p. 157-164. Tuebingen,
  Baden-Wurttemberg, Germany, 6-8 June 2008",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article describes the design of a common syntactic description for the
core grammar of a group of related dialects. The common description does not
rely on an abstract sub-linguistic structure like a metagrammar: it consists in
a single FS-LTAG where the actual specific language is included as one of the
attributes in the set of attribute types defined for the features. When the
lang attribute is instantiated, the selected subset of the grammar is
equivalent to the grammar of one dialect. When it is not, we have a model of a
hybrid multidialectal linguistic system. This principle is used for a group of
creole languages of the West-Atlantic area, namely the French-based Creoles of
Haiti, Guadeloupe, Martinique and French Guiana.
","[{'version': 'v1', 'created': 'Tue, 7 Oct 2008 14:50:59 GMT'}]",2008-10-08,"[['Vaillant', 'Pascal', '']]"
114,810.1212,Pascal Vaillant,"Pascal Vaillant, Richard Nock and Claudia Henry","Analyse spectrale des textes: d\'etection automatique des fronti\`eres
  de langue et de discours","In French. 10 pages, 5 figures, LaTeX 2e using EPSF and custom
  package taln2006.sty (designed by Pierre Zweigenbaum, ATALA). Proceedings of
  the 13th annual French-speaking conference on Natural Language Processing:
  `Traitement Automatique des Langues Naturelles' (TALN 2006), Louvain
  (Leuven), Belgium, 10-13 April 2003","Verbum ex machina: Actes de la 13eme conference annuelle sur le
  Traitement Automatique des Langues Naturelles (TALN 2006), p. 619-629.
  Louvain (Leuven), Belgique, 10-13 avril 2006",,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a theoretical framework within which information on the vocabulary
of a given corpus can be inferred on the basis of statistical information
gathered on that corpus. Inferences can be made on the categories of the words
in the vocabulary, and on their syntactical properties within particular
languages. Based on the same statistical data, it is possible to build matrices
of syntagmatic similarity (bigram transition matrices) or paradigmatic
similarity (probability for any pair of words to share common contexts). When
clustered with respect to their syntagmatic similarity, words tend to group
into sublanguage vocabularies, and when clustered with respect to their
paradigmatic similarity, into syntactic or semantic classes. Experiments have
explored the first of these two possibilities. Their results are interpreted in
the frame of a Markov chain modelling of the corpus' generative processe(s): we
show that the results of a spectral analysis of the transition matrix can be
interpreted as probability distributions of words within clusters. This method
yields a soft clustering of the vocabulary into sublanguages which contribute
to the generation of heterogeneous corpora. As an application, we show how
multilingual texts can be visually segmented into linguistically homogeneous
segments. Our method is specifically useful in the case of related languages
which happened to be mixed in corpora.
","[{'version': 'v1', 'created': 'Tue, 7 Oct 2008 15:25:31 GMT'}]",2008-10-08,"[['Vaillant', 'Pascal', ''], ['Nock', 'Richard', ''], ['Henry', 'Claudia', '']]"
115,810.1261,Pascal Vaillant,"Richard Nock, Pascal Vaillant, Frank Nielsen and Claudia Henry","Soft Uncoupling of Markov Chains for Permeable Language Distinction: A
  New Algorithm","6 pages, 7 embedded figures, LaTeX 2e using the ecai2006.cls document
  class and the algorithm2e.sty style file (+ standard packages like epsfig,
  amsmath, amssymb, amsfonts...). Extends the short version contained in the
  ECAI 2006 proceedings","ECAI 2006: 17th European Conference on Artificial Intelligence.
  Riva del Garda, Italy, 29 August - 1st September 2006",,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Without prior knowledge, distinguishing different languages may be a hard
task, especially when their borders are permeable. We develop an extension of
spectral clustering -- a powerful unsupervised classification toolbox -- that
is shown to resolve accurately the task of soft language distinction. At the
heart of our approach, we replace the usual hard membership assignment of
spectral clustering by a soft, probabilistic assignment, which also presents
the advantage to bypass a well-known complexity bottleneck of the method.
Furthermore, our approach relies on a novel, convenient construction of a
Markov chain out of a corpus. Extensive experiments with a readily available
system clearly display the potential of the method, which brings a visually
appealing soft distinction of languages that may define altogether a whole
corpus.
","[{'version': 'v1', 'created': 'Tue, 7 Oct 2008 18:09:07 GMT'}]",2008-10-08,"[['Nock', 'Richard', ''], ['Vaillant', 'Pascal', ''], ['Nielsen', 'Frank', ''], ['Henry', 'Claudia', '']]"
116,810.3125,{\L}ukasz D{\ke}bowski,{\L}ukasz D\k{e}bowski,"On the Vocabulary of Grammar-Based Codes and the Logical Consistency of
  Texts","24 pages, no figures","IEEE Transactions on Information Theory 57:4589-4599, 2011",10.1109/TIT.2011.2145170,,cs.IT cs.CL math.IT,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The article presents a new interpretation for Zipf-Mandelbrot's law in
natural language which rests on two areas of information theory. Firstly, we
construct a new class of grammar-based codes and, secondly, we investigate
properties of strongly nonergodic stationary processes. The motivation for the
joint discussion is to prove a proposition with a simple informal statement: If
a text of length $n$ describes $n^\beta$ independent facts in a repetitive way
then the text contains at least $n^\beta/\log n$ different words, under
suitable conditions on $n$. In the formal statement, two modeling postulates
are adopted. Firstly, the words are understood as nonterminal symbols of the
shortest grammar-based encoding of the text. Secondly, the text is assumed to
be emitted by a finite-energy strongly nonergodic source whereas the facts are
binary IID variables predictable in a shift-invariant way.
","[{'version': 'v1', 'created': 'Fri, 17 Oct 2008 16:32:17 GMT'}, {'version': 'v2', 'created': 'Fri, 31 Oct 2008 11:57:34 GMT'}, {'version': 'v3', 'created': 'Fri, 6 Nov 2009 20:47:24 GMT'}, {'version': 'v4', 'created': 'Tue, 26 Oct 2010 15:47:45 GMT'}, {'version': 'v5', 'created': 'Mon, 7 Feb 2011 16:48:23 GMT'}]",2020-03-11,"[['Dębowski', 'Łukasz', '']]"
117,810.3416,Elka Korutcheva,K.Koroutchev and E.Korutcheva,Text as Statistical Mechanics Object,,,,,cs.CL physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this article we present a model of human written text based on statistical
mechanics approach by deriving the potential energy for different parts of the
text using large text corpus. We have checked the results numerically and found
that the specific heat parameter effectively separates the closed class words
from the specific terms used in the text.
","[{'version': 'v1', 'created': 'Sun, 19 Oct 2008 17:34:33 GMT'}]",2008-10-21,"[['Koroutchev', 'K.', ''], ['Korutcheva', 'E.', '']]"
118,810.3442,Adam Lipowski,Adam Lipowski and Dorota Lipowska,Language structure in the n-object naming game,minor changes,"Phys. Rev. E 80, 056107 (2009)",10.1103/PhysRevE.80.056107,,cs.CL cs.MA physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We examine a naming game with two agents trying to establish a common
vocabulary for n objects. Such efforts lead to the emergence of language that
allows for an efficient communication and exhibits some degree of homonymy and
synonymy. Although homonymy reduces the communication efficiency, it seems to
be a dynamical trap that persists for a long, and perhaps indefinite, time. On
the other hand, synonymy does not reduce the efficiency of communication, but
appears to be only a transient feature of the language. Thus, in our model the
role of synonymy decreases and in the long-time limit it becomes negligible. A
similar rareness of synonymy is observed in present natural languages. The role
of noise, that distorts the communicated words, is also examined. Although, in
general, the noise reduces the communication efficiency, it also regroups the
words so that they are more evenly distributed within the available ""verbal""
space.
","[{'version': 'v1', 'created': 'Sun, 19 Oct 2008 23:59:37 GMT'}, {'version': 'v2', 'created': 'Sat, 21 Nov 2009 18:15:28 GMT'}]",2015-05-13,"[['Lipowski', 'Adam', ''], ['Lipowska', 'Dorota', '']]"
119,810.4616,Claudine Brucks,"Claudine Brucks, Christoph Schommer",Assembling Actor-based Mind-Maps from Text Stream,"12 pages, 8 Figures","Summary of the Master Thesis ""Actor-based Mind-map learning from
  Text Streams"". Dept. of Computer Science and Communication, University of
  Luxembourg, 2008",,,cs.CL cs.DL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For human beings, the processing of text streams of unknown size leads
generally to problems because e.g. noise must be selected out, information be
tested for its relevance or redundancy, and linguistic phenomenon like
ambiguity or the resolution of pronouns be advanced. Putting this into
simulation by using an artificial mind-map is a challenge, which offers the
gate for a wide field of applications like automatic text summarization or
punctual retrieval. In this work we present a framework that is a first step
towards an automatic intellect. It aims at assembling a mind-map based on
incoming text streams and on a subject-verb-object strategy, having the verb as
an interconnection between the adjacent nouns. The mind-map's performance is
enriched by a pronoun resolution engine that bases on the work of D. Klein, and
C. D. Manning.
","[{'version': 'v1', 'created': 'Sat, 25 Oct 2008 16:00:08 GMT'}]",2008-10-28,"[['Brucks', 'Claudine', ''], ['Schommer', 'Christoph', '']]"
120,810.4952,Adam Lipowski,Adam Lipowski and Dorota Lipowska,Computational modelling of evolution: ecosystems and language,"37 pages, proceedings of the conference ""From Genetics to
  Mathematics"" (Zbaszyn, Poland, October-2007)","Series on Advances in Mathematics for Applied Sciences - vol.79
  (2009)",,,q-bio.PE cs.CL physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, computational modelling became a very important research tool that
enables us to study problems that for decades evaded scientific analysis.
Evolutionary systems are certainly examples of such problems: they are composed
of many units that might reproduce, diffuse, mutate, die, or in some cases for
example communicate. These processes might be of some adaptive value, they
influence each other and occur on various time scales. That is why such systems
are so difficult to study. In this paper we briefly review some computational
approaches, as well as our contributions, to the evolution of ecosystems and
language. We start from Lotka-Volterra equations and the modelling of simple
two-species prey-predator systems. Such systems are canonical example for
studying oscillatory behaviour in competitive populations. Then we describe
various approaches to study long-term evolution of multi-species ecosystems. We
emphasize the need to use models that take into account both ecological and
evolutionary processes. Finally, we address the problem of the emergence and
development of language. It is becoming more and more evident that any theory
of language origin and development must be consistent with darwinian principles
of evolution. Consequently, a number of techniques developed for modelling
evolution of complex ecosystems are being applied to the problem of language.
We briefly review some of these approaches.
","[{'version': 'v1', 'created': 'Mon, 27 Oct 2008 23:20:11 GMT'}]",2009-07-04,"[['Lipowski', 'Adam', ''], ['Lipowska', 'Dorota', '']]"
121,811.0453,Cynthia Wagner CW,"Cynthia Wagner, and Christoph Schommer",CoZo+ - A Content Zoning Engine for textual documents,"4 pages, 4 figures",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Content zoning can be understood as a segmentation of textual documents into
zones. This is inspired by [6] who initially proposed an approach for the
argumentative zoning of textual documents. With the prototypical CoZo+ engine,
we focus on content zoning towards an automatic processing of textual streams
while considering only the actors as the zones. We gain information that can be
used to realize an automatic recognition of content for pre-defined actors. We
understand CoZo+ as a necessary pre-step towards an automatic generation of
summaries and to make intellectual ownership of documents detectable.
","[{'version': 'v1', 'created': 'Tue, 4 Nov 2008 09:08:32 GMT'}]",2008-11-05,"[['Wagner', 'Cynthia', ''], ['Schommer', 'Christoph', '']]"
122,811.0579,Gilles Serasset,"Gilles s\'erasset (IMAG, Clips - Imag, Lig), Christian Boitet (IMAG,
  Clips - Imag, Lig)","UNL-French deconversion as transfer & generation from an interlingua
  with possible quality enhancement through offline human interaction",,"MACHINE TRANSLATION SUMMIT VII, Singapour : Singapour (1999)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the architecture of the UNL-French deconverter, which ""generates""
from the UNL interlingua by first""localizing"" the UNL form for French, within
UNL, and then applying slightly adapted but classical transfer and generation
techniques, implemented in GETA's Ariane-G5 environment, supplemented by some
UNL-specific tools. Online interaction can be used during deconversion to
enhance output quality and is now used for development purposes. We show how
interaction could be delayed and embedded in the postedition phase, which would
then interact not directly with the output text, but indirectly with several
components of the deconverter. Interacting online or offline can improve the
quality not only of the utterance at hand, but also of the utterances processed
later, as various preferences may be automatically changed to let the
deconverter ""learn"".
","[{'version': 'v1', 'created': 'Tue, 4 Nov 2008 19:31:58 GMT'}]",2008-11-05,"[['sérasset', 'Gilles', '', 'IMAG, Clips - Imag, Lig'], ['Boitet', 'Christian', '', 'IMAG,\n  Clips - Imag, Lig']]"
123,811.126,R K Bisht,"Raj Kishor Bisht, H.S.Dhami",The Application of Fuzzy Logic to Collocation Extraction,"13 pages,5 figures,5 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Collocations are important for many tasks of Natural language processing such
as information retrieval, machine translation, computational lexicography etc.
So far many statistical methods have been used for collocation extraction.
Almost all the methods form a classical crisp set of collocation. We propose a
fuzzy logic approach of collocation extraction to form a fuzzy set of
collocations in which each word combination has a certain grade of membership
for being collocation. Fuzzy logic provides an easy way to express natural
language into fuzzy logic rules. Two existing methods; Mutual information and
t-test have been utilized for the input of the fuzzy inference system. The
resulting membership function could be easily seen and demonstrated. To show
the utility of the fuzzy logic some word pairs have been examined as an
example. The working data has been based on a corpus of about one million words
contained in different novels constituting project Gutenberg available on
www.gutenberg.org. The proposed method has all the advantages of the two
methods, while overcoming their drawbacks. Hence it provides a better result
than the two methods.
","[{'version': 'v1', 'created': 'Sat, 8 Nov 2008 10:44:43 GMT'}]",2008-11-11,"[['Bisht', 'Raj Kishor', ''], ['Dhami', 'H. S.', '']]"
124,811.4717,Daniel Racoceanu,"Roxana Teodorescu (UPT, LAB), Daniel Racoceanu (LAB, IPAAL), Wee-Kheng
  Leow (IPAAL, NUS), Vladimir Cretu (UPT)","Prospective Study for Semantic Inter-Media Fusion in Content-Based
  Medical Image Retrieval",11 pages,,,Onco-media Teodorescu 2008,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One important challenge in modern Content-Based Medical Image Retrieval
(CBMIR) approaches is represented by the semantic gap, related to the
complexity of the medical knowledge. Among the methods that are able to close
this gap in CBMIR, the use of medical thesauri/ontologies has interesting
perspectives due to the possibility of accessing on-line updated relevant
webservices and to extract real-time medical semantic structured information.
The CBMIR approach proposed in this paper uses the Unified Medical Language
System's (UMLS) Metathesaurus to perform a semantic indexing and fusion of
medical media. This fusion operates before the query processing (retrieval) and
works at an UMLS-compliant conceptual indexing level. Our purpose is to study
various techniques related to semantic data alignment, preprocessing, fusion,
clustering and retrieval, by evaluating the various techniques and highlighting
future research directions. The alignment and the preprocessing are based on
partial text/image retrieval feedback and on the data structure. We analyze
various probabilistic, fuzzy and evidence-based approaches for the fusion
process and different similarity functions for the retrieval process. All the
proposed methods are evaluated on the Cross Language Evaluation Forum's (CLEF)
medical image retrieval benchmark, by focusing also on a more homogeneous
component medical image database: the Pathology Education Instructional
Resource (PEIR).
","[{'version': 'v1', 'created': 'Fri, 28 Nov 2008 13:30:23 GMT'}]",2008-12-01,"[['Teodorescu', 'Roxana', '', 'UPT, LAB'], ['Racoceanu', 'Daniel', '', 'LAB, IPAAL'], ['Leow', 'Wee-Kheng', '', 'IPAAL, NUS'], ['Cretu', 'Vladimir', '', 'UPT']]"
125,812.307,Alex Arenas,"J. Borge, A. Arenas","A Computational Model to Disentangle Semantic Information Embedded in
  Word Association Norms","9 pages, 3 figures",,,,cs.CL cs.AI physics.data-an physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Two well-known databases of semantic relationships between pairs of words
used in psycholinguistics, feature-based and association-based, are studied as
complex networks. We propose an algorithm to disentangle feature based
relationships from free association semantic networks. The algorithm uses the
rich topology of the free association semantic network to produce a new set of
relationships between words similar to those observed in feature production
norms.
","[{'version': 'v1', 'created': 'Tue, 16 Dec 2008 14:24:23 GMT'}]",2008-12-17,"[['Borge', 'J.', ''], ['Arenas', 'A.', '']]"
126,812.4446,Peter Turney,Peter D. Turney (National Research Council of Canada),The Latent Relation Mapping Engine: Algorithm and Experiments,related work available at http://purl.org/peter.turney/,"Journal of Artificial Intelligence Research, (2008), 33, 615-655",10.1613/jair.2693,NRC-50738,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many AI researchers and cognitive scientists have argued that analogy is the
core of cognition. The most influential work on computational modeling of
analogy-making is Structure Mapping Theory (SMT) and its implementation in the
Structure Mapping Engine (SME). A limitation of SME is the requirement for
complex hand-coded representations. We introduce the Latent Relation Mapping
Engine (LRME), which combines ideas from SME and Latent Relational Analysis
(LRA) in order to remove the requirement for hand-coded representations. LRME
builds analogical mappings between lists of words, using a large corpus of raw
text to automatically discover the semantic relations among the words. We
evaluate LRME on a set of twenty analogical mapping problems, ten based on
scientific analogies and ten based on common metaphors. LRME achieves
human-level performance on the twenty problems. We compare LRME with a variety
of alternative approaches and find that they are not able to reach the same
level of performance.
","[{'version': 'v1', 'created': 'Tue, 23 Dec 2008 20:08:53 GMT'}]",2020-08-20,"[['Turney', 'Peter D.', '', 'National Research Council of Canada']]"
127,901.2216,Animesh Mukherjee,"Animesh Mukherjee, Monojit Choudhury and Ravi Kannan","Discovering Global Patterns in Linguistic Networks through Spectral
  Analysis: A Case Study of the Consonant Inventories",In the proceedings of EACL 2009,,,,cs.CL physics.data-an,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research has shown that language and the socio-cognitive phenomena
associated with it can be aptly modeled and visualized through networks of
linguistic entities. However, most of the existing works on linguistic networks
focus only on the local properties of the networks. This study is an attempt to
analyze the structure of languages via a purely structural technique, namely
spectral analysis, which is ideally suited for discovering the global
correlations in a network. Application of this technique to PhoNet, the
co-occurrence network of consonants, not only reveals several natural
linguistic principles governing the structure of the consonant inventories, but
is also able to quantify their relative importance. We believe that this
powerful technique can be successfully applied, in general, to study the
structure of natural languages.
","[{'version': 'v1', 'created': 'Thu, 15 Jan 2009 10:22:28 GMT'}]",2009-01-18,"[['Mukherjee', 'Animesh', ''], ['Choudhury', 'Monojit', ''], ['Kannan', 'Ravi', '']]"
128,901.2349,Eduardo G. Altmann,"Eduardo G. Altmann, Janet B. Pierrehumbert, and Adilson E. Motter","Beyond word frequency: Bursts, lulls, and scaling in the temporal
  distributions of words",,PLoS ONE 4 (11): e7678 (2009),10.1371/journal.pone.0007678,,cs.CL cond-mat.dis-nn physics.data-an physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Background: Zipf's discovery that word frequency distributions obey a power
law established parallels between biological and physical processes, and
language, laying the groundwork for a complex systems perspective on human
communication. More recent research has also identified scaling regularities in
the dynamics underlying the successive occurrences of events, suggesting the
possibility of similar findings for language as well.
  Methodology/Principal Findings: By considering frequent words in USENET
discussion groups and in disparate databases where the language has different
levels of formality, here we show that the distributions of distances between
successive occurrences of the same word display bursty deviations from a
Poisson process and are well characterized by a stretched exponential (Weibull)
scaling. The extent of this deviation depends strongly on semantic type -- a
measure of the logicality of each word -- and less strongly on frequency. We
develop a generative model of this behavior that fully determines the dynamics
of word usage.
  Conclusions/Significance: Recurrence patterns of words are well described by
a stretched exponential distribution of recurrence times, an empirical scaling
that cannot be anticipated from Zipf's law. Because the use of words provides a
uniquely precise and powerful lens on human thought and activity, our findings
also have implications for other overt manifestations of collective human
dynamics.
","[{'version': 'v1', 'created': 'Thu, 15 Jan 2009 21:12:12 GMT'}, {'version': 'v2', 'created': 'Wed, 11 Nov 2009 16:07:23 GMT'}]",2009-11-11,"[['Altmann', 'Eduardo G.', ''], ['Pierrehumbert', 'Janet B.', ''], ['Motter', 'Adilson E.', '']]"
129,901.2924,Alvaro Corral,"Alvaro Corral (1), Ramon Ferrer-i-Cancho (2), Gemma Boleda (2), Albert
  Diaz-Guilera (3). ((1) Centre de Recerca Matematica, (2) U Politecnica
  Catalunya, (3) U Barcelona)",Universal Complex Structures in Written Language,Short paper,,,,physics.soc-ph cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Quantitative linguistics has provided us with a number of empirical laws that
characterise the evolution of languages and competition amongst them. In terms
of language usage, one of the most influential results is Zipf's law of word
frequencies. Zipf's law appears to be universal, and may not even be unique to
human language. However, there is ongoing controversy over whether Zipf's law
is a good indicator of complexity. Here we present an alternative approach that
puts Zipf's law in the context of critical phenomena (the cornerstone of
complexity in physics) and establishes the presence of a large scale
""attraction"" between successive repetitions of words. Moreover, this phenomenon
is scale-invariant and universal -- the pattern is independent of word
frequency and is observed in texts by different authors and written in
different languages. There is evidence, however, that the shape of the scaling
relation changes for words that play a key role in the text, implying the
existence of different ""universality classes"" in the repetition of words. These
behaviours exhibit striking parallels with complex catastrophic phenomena.
","[{'version': 'v1', 'created': 'Mon, 19 Jan 2009 21:19:55 GMT'}]",2009-01-21,"[['Corral', 'Alvaro', ''], ['Ferrer-i-Cancho', 'Ramon', ''], ['Boleda', 'Gemma', ''], ['Diaz-Guilera', 'Albert', ''], ['.', '', '']]"
130,901.3017,Ronojoy Adhikari,"Nisha Yadav, Hrishikesh Joglekar, Rajesh P. N. Rao, M. N. Vahia,
  Iravatham Mahadevan and R. Adhikari",Statistical analysis of the Indus script using $n$-grams,,,10.1371/journal.pone.0009506,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Indus script is one of the major undeciphered scripts of the ancient
world. The small size of the corpus, the absence of bilingual texts, and the
lack of definite knowledge of the underlying language has frustrated efforts at
decipherment since the discovery of the remains of the Indus civilisation.
Recently, some researchers have questioned the premise that the Indus script
encodes spoken language. Building on previous statistical approaches, we apply
the tools of statistical language processing, specifically $n$-gram Markov
chains, to analyse the Indus script for syntax. Our main results are that the
script has well-defined signs which begin and end texts, that there is
directionality and strong correlations in the sign order, and that there are
groups of signs which appear to have identical syntactic function. All these
require no {\it a priori} suppositions regarding the syntactic or semantic
content of the signs, but follow directly from the statistical analysis. Using
information theoretic measures, we find the information in the script to be
intermediate between that of a completely random and a completely fixed
ordering of signs. Our study reveals that the Indus script is a structured sign
system showing features of a formal language, but, at present, cannot
conclusively establish that it encodes {\it natural} language. Our $n$-gram
Markov model is useful for predicting signs which are missing or illegible in a
corpus of Indus texts. This work forms the basis for the development of a
stochastic grammar which can be used to explore the syntax of the Indus script
in greater detail.
","[{'version': 'v1', 'created': 'Tue, 20 Jan 2009 12:55:55 GMT'}]",2015-05-13,"[['Yadav', 'Nisha', ''], ['Joglekar', 'Hrishikesh', ''], ['Rao', 'Rajesh P. N.', ''], ['Vahia', 'M. N.', ''], ['Mahadevan', 'Iravatham', ''], ['Adhikari', 'R.', '']]"
131,901.3291,Jaroslaw Kwapien,"Stanislaw Drozdz, Jaroslaw Kwapien, Adam Orczyk",Approaching the linguistic complexity,to be published in conference proceedings,"Complex Sciences, Lect. Notes ICST vol.4, 1044-1050 (Springer,
  2009)",10.1007/978-3-642-02466-5_104,,cs.CL physics.data-an,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We analyze the rank-frequency distributions of words in selected English and
Polish texts. We compare scaling properties of these distributions in both
languages. We also study a few small corpora of Polish literary texts and find
that for a corpus consisting of texts written by different authors the basic
scaling regime is broken more strongly than in the case of comparable corpus
consisting of texts written by the same author. Similarly, for a corpus
consisting of texts translated into Polish from other languages the scaling
regime is broken more strongly than for a comparable corpus of native Polish
texts. Moreover, based on the British National Corpus, we consider the
rank-frequency distributions of the grammatically basic forms of words (lemmas)
tagged with their proper part of speech. We find that these distributions do
not scale if each part of speech is analyzed separately. The only part of
speech that independently develops a trace of scaling is verbs.
","[{'version': 'v1', 'created': 'Wed, 21 Jan 2009 15:24:59 GMT'}]",2015-11-11,"[['Drozdz', 'Stanislaw', ''], ['Kwapien', 'Jaroslaw', ''], ['Orczyk', 'Adam', '']]"
132,901.399,Bernard Jacquemin,"Bernard Jacquemin (LIMSI), Sabine Ploux (L2C2)",Du corpus au dictionnaire,,"Cahiers de Linguistique. Revue de sociolinguistique et de
  sociologie de la langue fran\c{c}aise 33, 1 (2008) 63-84",,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this article, we propose an automatic process to build multi-lingual
lexico-semantic resources. The goal of these resources is to browse
semantically textual information contained in texts of different languages.
This method uses a mathematical model called Atlas s\'emantiques in order to
represent the different senses of each word. It uses the linguistic relations
between words to create graphs that are projected into a semantic space. These
projections constitute semantic maps that denote the sense trends of each given
word. This model is fed with syntactic relations between words extracted from a
corpus. Therefore, the lexico-semantic resource produced describes all the
words and all their meanings observed in the corpus. The sense trends are
expressed by syntactic contexts, typical for a given meaning. The link between
each sense trend and the utterances used to build the sense trend are also
stored in an index. Thus all the instances of a word in a particular sense are
linked and can be browsed easily. And by using several corpora of different
languages, several resources are built that correspond with each other through
languages. It makes it possible to browse information through languages thanks
to syntactic contexts translations (even if some of them are partial).
","[{'version': 'v1', 'created': 'Mon, 26 Jan 2009 15:52:21 GMT'}]",2009-01-27,"[['Jacquemin', 'Bernard', '', 'LIMSI'], ['Ploux', 'Sabine', '', 'L2C2']]"
133,901.418,Bj{\o}rn Kjos-Hanssen,Bj{\o}rn Kjos-Hanssen and Alberto J. Evangelista,Google distance between words,"Presented at Frontiers in Undergraduate Research, University of
  Connecticut, 2006",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cilibrasi and Vitanyi have demonstrated that it is possible to extract the
meaning of words from the world-wide web. To achieve this, they rely on the
number of webpages that are found through a Google search containing a given
word and they associate the page count to the probability that the word appears
on a webpage. Thus, conditional probabilities allow them to correlate one word
with another word's meaning. Furthermore, they have developed a similarity
distance function that gauges how closely related a pair of words is. We
present a specific counterexample to the triangle inequality for this
similarity distance function.
","[{'version': 'v1', 'created': 'Tue, 27 Jan 2009 06:29:10 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Jan 2015 20:10:34 GMT'}]",2015-01-29,"[['Kjos-Hanssen', 'Bjørn', ''], ['Evangelista', 'Alberto J.', '']]"
134,901.4375,Peter Bruza,"P.D. Bruza, K. Kitto, D. Nelson, C. McEvoy","Extracting Spooky-activation-at-a-distance from Considerations of
  Entanglement","13 pages, 2 figures; To appear in Proceedings of the Third Quantum
  Interaction Symposium, Lecture Notes in Artificial Intelligence, vol 5494,
  Springer, 2009",,,,physics.data-an cs.CL quant-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Following an early claim by Nelson & McEvoy \cite{Nelson:McEvoy:2007}
suggesting that word associations can display `spooky action at a distance
behaviour', a serious investigation of the potentially quantum nature of such
associations is currently underway. This paper presents a simple quantum model
of a word association system. It is shown that a quantum model of word
entanglement can recover aspects of both the Spreading Activation equation and
the Spooky-activation-at-a-distance equation, both of which are used to model
the activation level of words in human memory.
","[{'version': 'v1', 'created': 'Tue, 27 Jan 2009 23:59:59 GMT'}]",2009-01-29,"[['Bruza', 'P. D.', ''], ['Kitto', 'K.', ''], ['Nelson', 'D.', ''], ['McEvoy', 'C.', '']]"
135,901.4784,Fabio G. Guerrero Moreno,Fabio G. Guerrero,On the Entropy of Written Spanish,Submitted to the IEEE Transactions on Information Theory,"Revista Colombiana de Estadistica (RCE), Vol. 35, No. 3, Dec.
  2012, pp 423-440",,,cs.CL cs.IT math.IT,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper reports on results on the entropy of the Spanish language. They
are based on an analysis of natural language for n-word symbols (n = 1 to 18),
trigrams, digrams, and characters. The results obtained in this work are based
on the analysis of twelve different literary works in Spanish, as well as a
279917 word news file provided by the Spanish press agency EFE. Entropy values
are calculated by a direct method using computer processing and the probability
law of large numbers. Three samples of artificial Spanish language produced by
a first-order model software source are also analyzed and compared with natural
Spanish language.
","[{'version': 'v1', 'created': 'Fri, 30 Jan 2009 03:46:01 GMT'}]",2013-01-15,"[['Guerrero', 'Fabio G.', '']]"
136,902.0606,M. Angeles Serrano,"M. Angeles Serrano, Alessandro Flammini, and Filippo Menczer",Beyond Zipf's law: Modeling the structure of human language,"9 pages, 4 figures",,,,cs.CL physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Human language, the most powerful communication system in history, is closely
associated with cognition. Written text is one of the fundamental
manifestations of language, and the study of its universal regularities can
give clues about how our brains process information and how we, as a society,
organize and share it. Still, only classical patterns such as Zipf's law have
been explored in depth. In contrast, other basic properties like the existence
of bursts of rare words in specific documents, the topical organization of
collections, or the sublinear growth of vocabulary size with the length of a
document, have only been studied one by one and mainly applying heuristic
methodologies rather than basic principles and general mechanisms. As a
consequence, there is a lack of understanding of linguistic processes as
complex emergent phenomena. Beyond Zipf's law for word frequencies, here we
focus on Heaps' law, burstiness, and the topicality of document collections,
which encode correlations within and across documents absent in random null
models. We introduce and validate a generative model that explains the
simultaneous emergence of all these patterns from simple rules. As a result, we
find a connection between the bursty nature of rare words and the topical
organization of texts and identify dynamic word ranking and memory across
documents as key mechanisms explaining the non trivial organization of written
text. Our research can have broad implications and practical applications in
computer science, cognitive science, and linguistics.
","[{'version': 'v1', 'created': 'Tue, 3 Feb 2009 21:04:33 GMT'}]",2009-02-05,"[['Serrano', 'M. Angeles', ''], ['Flammini', 'Alessandro', ''], ['Menczer', 'Filippo', '']]"
137,902.1033,Sylvain Raybaud,"Sylvain Raybaud (INRIA Lorraine - LORIA), Caroline Lavecchia (INRIA
  Lorraine - LORIA), David Langlois (INRIA Lorraine - LORIA), Kamel Sma\""ili
  (INRIA Lorraine - LORIA)",New Confidence Measures for Statistical Machine Translation,,"International Conference On Agents and Artificial Intelligence -
  ICAART 09 (2009)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A confidence measure is able to estimate the reliability of an hypothesis
provided by a machine translation system. The problem of confidence measure can
be seen as a process of testing : we want to decide whether the most probable
sequence of words provided by the machine translation system is correct or not.
In the following we describe several original word-level confidence measures
for machine translation, based on mutual information, n-gram language model and
lexical features language model. We evaluate how well they perform individually
or together, and show that using a combination of confidence measures based on
mutual information yields a classification error rate as low as 25.1% with an
F-measure of 0.708.
","[{'version': 'v1', 'created': 'Fri, 6 Feb 2009 09:28:58 GMT'}]",2009-02-09,"[['Raybaud', 'Sylvain', '', 'INRIA Lorraine - LORIA'], ['Lavecchia', 'Caroline', '', 'INRIA\n  Lorraine - LORIA'], ['Langlois', 'David', '', 'INRIA Lorraine - LORIA'], ['Smaïli', 'Kamel', '', 'INRIA Lorraine - LORIA']]"
138,902.223,Ama\c{c} Herda\u{g}delen,Ama\c{c} Herda\u{g}delen and Marco Baroni,BagPack: A general framework to represent semantic relations,"Long paper presented at GEMS - Geometric Models of Natural Language
  Semantics, workshop held in conjunction with the 12th Conference of the
  European Chapter of the Association for Computational Linguistics (EACL-09),
  Athens, Greece",,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a way to represent word pairs instantiating arbitrary semantic
relations that keeps track of the contexts in which the words in the pair occur
both together and independently. The resulting features are of sufficient
generality to allow us, with the help of a standard supervised machine learning
algorithm, to tackle a variety of unrelated semantic tasks with good results
and almost no task-specific tailoring.
","[{'version': 'v1', 'created': 'Thu, 12 Feb 2009 23:02:06 GMT'}]",2009-02-16,"[['Herdağdelen', 'Amaç', ''], ['Baroni', 'Marco', '']]"
139,902.2345,Stergos Afantenos,Stergos D. Afantenos and Nicolas Hernandez,What's in a Message?,,"12th Conference of the European Chapter of the Association for
  Computational Linguistics (EACL 2009), workshop on Cognitive Aspects of
  Computational Language Acquisition. Athens, Greece",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we present the first step in a larger series of experiments for
the induction of predicate/argument structures. The structures that we are
inducing are very similar to the conceptual structures that are used in Frame
Semantics (such as FrameNet). Those structures are called messages and they
were previously used in the context of a multi-document summarization system of
evolving events. The series of experiments that we are proposing are
essentially composed from two stages. In the first stage we are trying to
extract a representative vocabulary of words. This vocabulary is later used in
the second stage, during which we apply to it various clustering approaches in
order to identify the clusters of predicates and arguments--or frames and
semantic roles, to use the jargon of Frame Semantics. This paper presents in
detail and evaluates the first stage.
","[{'version': 'v1', 'created': 'Fri, 13 Feb 2009 17:08:10 GMT'}]",2009-02-16,"[['Afantenos', 'Stergos D.', ''], ['Hernandez', 'Nicolas', '']]"
140,902.3072,Eric Laporte,"Eric Laporte (IGM-LabInfo), Elisabete Ranchhod (ONSET-CEL), Anastasia
  Yannacopoulou (IGM-LabInfo)",Syntactic variation of support verb constructions,,"Lingvisticae Investigationes 31, 2 (2008) 173-185",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We report experiments about the syntactic variations of support verb
constructions, a special type of multiword expressions (MWEs) containing
predicative nouns. In these expressions, the noun can occur with or without the
verb, with no clear-cut semantic difference. We extracted from a large French
corpus a set of examples of the two situations and derived statistical results
from these data. The extraction involved large-coverage language resources and
finite-state techniques. The results show that, most frequently, predicative
nouns occur without a support verb. This fact has consequences on methods of
extracting or recognising MWEs.
","[{'version': 'v1', 'created': 'Wed, 18 Feb 2009 08:51:28 GMT'}]",2009-02-19,"[['Laporte', 'Eric', '', 'IGM-LabInfo'], ['Ranchhod', 'Elisabete', '', 'ONSET-CEL'], ['Yannacopoulou', 'Anastasia', '', 'IGM-LabInfo']]"
141,902.406,Ken Yamamoto,"Ken Yamamoto, Yoshihiro Yamazaki",Network of two-Chinese-character compound words in Japanese language,,"Physica A 388, 2555-2560 (2009)",10.1016/j.physa.2009.02.032,,cs.CL physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Some statistical properties of a network of two-Chinese-character compound
words in Japanese language are reported. In this network, a node represents a
Chinese character and an edge represents a two-Chinese-character compound word.
It is found that this network has properties of ""small-world"" and ""scale-free.""
A network formed by only Chinese characters for common use ({\it joyo-kanji} in
Japanese), which is regarded as a subclass of the original network, also has
small-world property. However, a degree distribution of the network exhibits no
clear power law. In order to reproduce disappearance of the power-law property,
a model for a selecting process of the Chinese characters for common use is
proposed.
","[{'version': 'v1', 'created': 'Tue, 24 Feb 2009 04:53:49 GMT'}]",2012-05-15,"[['Yamamoto', 'Ken', ''], ['Yamazaki', 'Yoshihiro', '']]"
142,903.2792,Manuel Cebrian,"Kostadin Koroutchev, Jian Shen, Elka Koroutcheva and Manuel Cebrian",Thermodynamics of Information Retrieval,"12 pages, 7 figures",,,,cs.IT cs.CL cs.SI math.IT,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we suggest a parameterized statistical model (the gamma
distribution) for the frequency of word occurrences in long strings of English
text and use this model to build a corresponding thermodynamic picture by
constructing the partition function. We then use our partition function to
compute thermodynamic quantities such as the free energy and the specific heat.
In this approach, the parameters of the word frequency model vary from word to
word so that each word has a different corresponding thermodynamics and we
suggest that differences in the specific heat reflect differences in how the
words are used in language, differentiating keywords from common and function
words. Finally, we apply our thermodynamic picture to the problem of retrieval
of texts based on keywords and suggest some advantages over traditional
information retrieval methods.
","[{'version': 'v1', 'created': 'Mon, 16 Mar 2009 16:16:42 GMT'}, {'version': 'v2', 'created': 'Mon, 14 Feb 2011 01:07:57 GMT'}, {'version': 'v3', 'created': 'Sun, 27 Feb 2011 10:36:25 GMT'}]",2011-03-01,"[['Koroutchev', 'Kostadin', ''], ['Shen', 'Jian', ''], ['Koroutcheva', 'Elka', ''], ['Cebrian', 'Manuel', '']]"
143,903.5168,Rakesh Pandey,"Rakesh Pandey, H.S. Dhami","Mathematical Model for Transformation of Sentences from Active Voice to
  Passive Voice",,,,,cs.CL,http://creativecommons.org/licenses/by/3.0/,"  Formal work in linguistics has both produced and used important mathematical
tools. Motivated by a survey of models for context and word meaning, syntactic
categories, phrase structure rules and trees, an attempt is being made in the
present paper to present a mathematical model for structuring of sentences from
active voice to passive voice, which is is the form of a transitive verb whose
grammatical subject serves as the patient, receiving the action of the verb.
  For this purpose we have parsed all sentences of a corpus and have generated
Boolean groups for each of them. It has been observed that when we take
constituents of the sentences as subgroups, the sequences of phrases form
permutation roups. Application of isomorphism property yields permutation
mapping between the important subgroups. It has resulted in a model for
transformation of sentences from active voice to passive voice. A computer
program has been written to enable the software developers to evolve grammar
software for sentence transformations.
","[{'version': 'v1', 'created': 'Mon, 30 Mar 2009 09:45:20 GMT'}]",2009-03-31,"[['Pandey', 'Rakesh', ''], ['Dhami', 'H. S.', '']]"
144,904.1289,Animesh Mukherjee,"Monojit Choudhury, Animesh Mukherjee, Anupam Basu, Niloy Ganguly,
  Ashish Garg, Vaibhav Jalan","Language Diversity across the Consonant Inventories: A Study in the
  Framework of Complex Networks","In EACL 2009 Workshop on Cognitive Aspects of Computational Language
  Acquisition",,,,cs.CL physics.comp-ph physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  n this paper, we attempt to explain the emergence of the linguistic diversity
that exists across the consonant inventories of some of the major language
families of the world through a complex network based growth model. There is
only a single parameter for this model that is meant to introduce a small
amount of randomness in the otherwise preferential attachment based growth
process. The experiments with this model parameter indicates that the choice of
consonants among the languages within a family are far more preferential than
it is across the families. The implications of this result are twofold -- (a)
there is an innate preference of the speakers towards acquiring certain
linguistic structures over others and (b) shared ancestry propels the stronger
preferential connection between the languages within a family than across them.
Furthermore, our observations indicate that this parameter might bear a
correlation with the period of existence of the language families under
investigation.
","[{'version': 'v1', 'created': 'Wed, 8 Apr 2009 08:57:43 GMT'}]",2009-04-09,"[['Choudhury', 'Monojit', ''], ['Mukherjee', 'Animesh', ''], ['Basu', 'Anupam', ''], ['Ganguly', 'Niloy', ''], ['Garg', 'Ashish', ''], ['Jalan', 'Vaibhav', '']]"
145,905.074,Ignacio Vega-Paez M en C,Gerardo Cisneros,"A FORTRAN coded regular expression Compiler for IBM 1130 Computing
  System","This version of REC is archaeological reconstruction of REC/A
  language on IBM1130 Simulator (SIMH IBM 1130 Emulator and Disk Monitor System
  R2V12) from Computer History Simulation Project (www.ibm1130.org), also see
  REC language is a live for Ignacio Vega-Paez","Acta Mexicana de Ciencia y Tecnologia Vol. IV No. 1, page 30-86,
  1970",,IBP-Memo 2008-12,cs.CL cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  REC (Regular Expression Compiler) is a concise programming language which
allows students to write programs without knowledge of the complicated syntax
of languages like FORTRAN and ALGOL. The language is recursive and contains
only four elements for control. This paper describes an interpreter of REC
written in FORTRAN.
","[{'version': 'v1', 'created': 'Wed, 6 May 2009 04:29:51 GMT'}]",2011-07-12,"[['Cisneros', 'Gerardo', '']]"
146,905.113,Juan-Manuel Torres-Moreno,"Florian Boudin, Patricia Velazquez-Morales and Juan-Manuel
  Torres-Moreno",Statistical Automatic Summarization in Organic Chemistry,"10 pages, 3 figures",,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an oriented numerical summarizer algorithm, applied to producing
automatic summaries of scientific documents in Organic Chemistry. We present
its implementation named Yachs (Yet Another Chemistry Summarizer) that combines
a specific document pre-processing with a sentence scoring method relying on
the statistical properties of documents. We show that Yachs achieves the best
results among several other summarizers on a corpus of Organic Chemistry
articles.
","[{'version': 'v1', 'created': 'Thu, 7 May 2009 20:21:45 GMT'}]",2009-05-11,"[['Boudin', 'Florian', ''], ['Velazquez-Morales', 'Patricia', ''], ['Torres-Moreno', 'Juan-Manuel', '']]"
147,905.1235,Serguei Mokhov,"Serguei A. Mokhov, Stephen Sinclair, Ian Cl\'ement, Dimitrios
  Nicolacopoulos (for the MARF R&D Group)","The Modular Audio Recognition Framework (MARF) and its Applications:
  Scientific and Software Engineering Notes","v2: add missing .ind file for index; 224 pages, 40 figures, 19
  tables; index. A comprehensive description of AI and PR algorithms and data
  structures, software engineering design and implementation, and experiments.
  Source revision is maintained in the CVS at http://marf.sf.net",,"10.1007/978-1-4020-8741-7_84 10.1007/978-3-540-68825-9_21
  10.1145/1370256.1370262",,cs.SD cs.CL cs.CV cs.MM cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  MARF is an open-source research platform and a collection of
voice/sound/speech/text and natural language processing (NLP) algorithms
written in Java and arranged into a modular and extensible framework
facilitating addition of new algorithms. MARF can run distributively over the
network and may act as a library in applications or be used as a source for
learning and extension. A few example applications are provided to show how to
use the framework. There is an API reference in the Javadoc format as well as
this set of accompanying notes with the detailed description of the
architectural design, algorithms, and applications. MARF and its applications
are released under a BSD-style license and is hosted at SourceForge.net. This
document provides the details and the insight on the internals of MARF and some
of the mentioned applications.
","[{'version': 'v1', 'created': 'Fri, 8 May 2009 14:42:03 GMT'}, {'version': 'v2', 'created': 'Sat, 25 Jul 2009 04:13:29 GMT'}]",2019-08-14,"[['Mokhov', 'Serguei A.', '', 'for the MARF R&D Group'], ['Sinclair', 'Stephen', '', 'for the MARF R&D Group'], ['Clément', 'Ian', '', 'for the MARF R&D Group'], ['Nicolacopoulos', 'Dimitrios', '', 'for the MARF R&D Group']]"
148,905.1609,Nabil Hathout,Nabil Hathout (CLLE),"Acquisition of morphological families and derivational series from a
  machine readable dictionary",proceedings of the 6th D\'ecembrettes,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper presents a linguistic and computational model aiming at making the
morphological structure of the lexicon emerge from the formal and semantic
regularities of the words it contains. The model is word-based. The proposed
morphological structure consists of (1) binary relations that connect each
headword with words that are morphologically related, and especially with the
members of its morphological family and its derivational series, and of (2) the
analogies that hold between the words. The model has been tested on the lexicon
of French using the TLFi machine readable dictionary.
","[{'version': 'v1', 'created': 'Mon, 11 May 2009 12:17:36 GMT'}]",2009-05-12,"[['Hathout', 'Nabil', '', 'CLLE']]"
149,905.299,Juan-Manuel Torres-Moreno,"Juan-Manuel Torres-Moreno and Pier-Luc St-Onge and Michel Gagnon and
  Marc El-B\`eze and Patrice Bellot","Automatic Summarization System coupled with a Question-Answering System
  (QAAS)","28 pages, 11 figures",,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To select the most relevant sentences of a document, it uses an optimal
decision algorithm that combines several metrics. The metrics processes,
weighting and extract pertinence sentences by statistical and informational
algorithms. This technique might improve a Question-Answering system, whose
function is to provide an exact answer to a question in natural language. In
this paper, we present the results obtained by coupling the Cortex summarizer
with a Question-Answering system (QAAS). Two configurations have been
evaluated. In the first one, a low compression level is selected and the
summarization system is only used as a noise filter. In the second
configuration, the system actually functions as a summarizer, with a very high
level of compression. Our results on French corpus demonstrate that the
coupling of Automatic Summarization system with a Question-Answering system is
promising. Then the system has been adapted to generate a customized summary
depending on the specific question. Tests on a french multi-document corpus
have been realized, and the personalized QAAS system obtains the best
performances.
","[{'version': 'v1', 'created': 'Mon, 18 May 2009 21:35:52 GMT'}]",2009-05-20,"[['Torres-Moreno', 'Juan-Manuel', ''], ['St-Onge', 'Pier-Luc', ''], ['Gagnon', 'Michel', ''], ['El-Bèze', 'Marc', ''], ['Bellot', 'Patrice', '']]"
150,905.3318,Maarten Hijzelendoorn,Maarten Hijzelendoorn and Crit Cremers,An Object-Oriented and Fast Lexicon for Semantic Generation,"Paper presented at the 18th Computational Linguistics In the
  Netherlands Meeting (CLIN), Nijmegen, 10 December 2007, 15pp",,,,cs.CL cs.DB cs.DS cs.IR cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper is about the technical design of a large computational lexicon,
its storage, and its access from a Prolog environment. Traditionally, efficient
access and storage of data structures is implemented by a relational database
management system. In Delilah, a lexicon-based NLP system, efficient access to
the lexicon by the semantic generator is vital. We show that our highly
detailed HPSG-style lexical specifications do not fit well in the Relational
Model, and that they cannot be efficiently retrieved. We argue that they fit
more naturally in the Object-Oriented Model. Although storage of objects is
redundant, we claim that efficient access is still possible by applying
indexing, and compression techniques from the Relational Model to the
Object-Oriented Model. We demonstrate that it is possible to implement
object-oriented storage and fast access in ISO Prolog.
","[{'version': 'v1', 'created': 'Wed, 20 May 2009 14:12:42 GMT'}]",2009-05-21,"[['Hijzelendoorn', 'Maarten', ''], ['Cremers', 'Crit', '']]"
151,704.2083,Hassan Satori,"H. Satori, M. Harti and N. Chenfour",Introduction to Arabic Speech Recognition Using CMUSphinx System,"4 pages, 3 figures and 2 tables, was in Information and Communication
  Technologies International Symposium proceeding ICTIS07 Fes (2007)",,,,cs.CL cs.AI,,"  In this paper Arabic was investigated from the speech recognition problem
point of view. We propose a novel approach to build an Arabic Automated Speech
Recognition System (ASR). This system is based on the open source CMU Sphinx-4,
from the Carnegie Mellon University. CMU Sphinx is a large-vocabulary;
speaker-independent, continuous speech recognition system based on discrete
Hidden Markov Models (HMMs). We build a model using utilities from the
OpenSource CMU Sphinx. We will demonstrate the possible adaptability of this
system to Arabic voice recognition.
","[{'version': 'v1', 'created': 'Tue, 17 Apr 2007 01:04:01 GMT'}]",2007-05-23,"[['Satori', 'H.', ''], ['Harti', 'M.', ''], ['Chenfour', 'N.', '']]"